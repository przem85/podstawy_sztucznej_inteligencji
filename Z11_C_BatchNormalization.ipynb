{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Zróbmy szybki preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Nauczmy model z BatchNormalization\n",
    "\n",
    "Pamiętaj, że \n",
    "\n",
    "* BatchNormalization powinno być dodane przed funkcją katywacji\n",
    "* ustaw parametr use_bias=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                500       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 10,251\n",
      "Trainable params: 9,931\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "history = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100, use_bias=False,input_shape=(X_train.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(50, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(10, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30162 samples, validate on 15060 samples\n",
      "Epoch 1/100\n",
      "30162/30162 [==============================] - 3s 87us/step - loss: 0.4616 - accuracy: 0.7800 - val_loss: 0.4866 - val_accuracy: 0.7782\n",
      "Epoch 2/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3846 - accuracy: 0.8124 - val_loss: 0.4668 - val_accuracy: 0.7756\n",
      "Epoch 3/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3772 - accuracy: 0.8171 - val_loss: 0.4768 - val_accuracy: 0.7626\n",
      "Epoch 4/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3741 - accuracy: 0.8183 - val_loss: 0.4842 - val_accuracy: 0.7618\n",
      "Epoch 5/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3666 - accuracy: 0.8235 - val_loss: 0.5267 - val_accuracy: 0.7596\n",
      "Epoch 6/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3602 - accuracy: 0.8297 - val_loss: 0.4937 - val_accuracy: 0.7762\n",
      "Epoch 7/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3571 - accuracy: 0.8306 - val_loss: 0.4801 - val_accuracy: 0.7954\n",
      "Epoch 8/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3563 - accuracy: 0.8307 - val_loss: 0.4764 - val_accuracy: 0.7790\n",
      "Epoch 9/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3533 - accuracy: 0.8340 - val_loss: 0.5450 - val_accuracy: 0.7597\n",
      "Epoch 10/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3515 - accuracy: 0.8338 - val_loss: 0.4783 - val_accuracy: 0.7746\n",
      "Epoch 11/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3495 - accuracy: 0.8330 - val_loss: 0.4813 - val_accuracy: 0.7779\n",
      "Epoch 12/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3466 - accuracy: 0.8345 - val_loss: 0.4988 - val_accuracy: 0.7622\n",
      "Epoch 13/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3430 - accuracy: 0.8386 - val_loss: 0.4238 - val_accuracy: 0.7776\n",
      "Epoch 14/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3429 - accuracy: 0.8400 - val_loss: 0.4519 - val_accuracy: 0.7833\n",
      "Epoch 15/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3420 - accuracy: 0.8375 - val_loss: 0.4922 - val_accuracy: 0.7734\n",
      "Epoch 16/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.3419 - accuracy: 0.8378 - val_loss: 0.4685 - val_accuracy: 0.7622\n",
      "Epoch 17/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3396 - accuracy: 0.8406 - val_loss: 0.5018 - val_accuracy: 0.7614\n",
      "Epoch 18/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.3401 - accuracy: 0.8393 - val_loss: 0.4616 - val_accuracy: 0.7659\n",
      "Epoch 19/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3389 - accuracy: 0.8416 - val_loss: 0.5247 - val_accuracy: 0.7622\n",
      "Epoch 20/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.3377 - accuracy: 0.8392 - val_loss: 0.5475 - val_accuracy: 0.7619\n",
      "Epoch 21/100\n",
      "30162/30162 [==============================] - 2s 65us/step - loss: 0.3372 - accuracy: 0.8426 - val_loss: 0.4575 - val_accuracy: 0.7924\n",
      "Epoch 22/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.3379 - accuracy: 0.8409 - val_loss: 0.4990 - val_accuracy: 0.7622\n",
      "Epoch 23/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3361 - accuracy: 0.8413 - val_loss: 0.4421 - val_accuracy: 0.7736\n",
      "Epoch 24/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3369 - accuracy: 0.8416 - val_loss: 0.4937 - val_accuracy: 0.7622\n",
      "Epoch 25/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3337 - accuracy: 0.8435 - val_loss: 0.4912 - val_accuracy: 0.7614\n",
      "Epoch 26/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3341 - accuracy: 0.8427 - val_loss: 0.5728 - val_accuracy: 0.7543\n",
      "Epoch 27/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3342 - accuracy: 0.8427 - val_loss: 0.4224 - val_accuracy: 0.7934\n",
      "Epoch 28/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3330 - accuracy: 0.8426 - val_loss: 0.4871 - val_accuracy: 0.7718\n",
      "Epoch 29/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3332 - accuracy: 0.8426 - val_loss: 0.4747 - val_accuracy: 0.7809\n",
      "Epoch 30/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.3320 - accuracy: 0.8449 - val_loss: 0.4857 - val_accuracy: 0.7622\n",
      "Epoch 31/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3347 - accuracy: 0.8426 - val_loss: 0.4844 - val_accuracy: 0.7734\n",
      "Epoch 32/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3318 - accuracy: 0.8436 - val_loss: 0.4634 - val_accuracy: 0.7651\n",
      "Epoch 33/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3313 - accuracy: 0.8436 - val_loss: 0.5428 - val_accuracy: 0.7622\n",
      "Epoch 34/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3295 - accuracy: 0.8456 - val_loss: 0.4799 - val_accuracy: 0.7622\n",
      "Epoch 35/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3289 - accuracy: 0.8445 - val_loss: 0.5055 - val_accuracy: 0.7619\n",
      "Epoch 36/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3308 - accuracy: 0.8443 - val_loss: 0.4845 - val_accuracy: 0.7624\n",
      "Epoch 37/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3304 - accuracy: 0.8428 - val_loss: 0.5098 - val_accuracy: 0.7616\n",
      "Epoch 38/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.3300 - accuracy: 0.8441 - val_loss: 0.5441 - val_accuracy: 0.7612\n",
      "Epoch 39/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3304 - accuracy: 0.8443 - val_loss: 0.5030 - val_accuracy: 0.7617\n",
      "Epoch 40/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3282 - accuracy: 0.8468 - val_loss: 0.5936 - val_accuracy: 0.7596\n",
      "Epoch 41/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3299 - accuracy: 0.8441 - val_loss: 0.4557 - val_accuracy: 0.7714\n",
      "Epoch 42/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3293 - accuracy: 0.8441 - val_loss: 0.4909 - val_accuracy: 0.7638\n",
      "Epoch 43/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3271 - accuracy: 0.8455 - val_loss: 0.4827 - val_accuracy: 0.7735\n",
      "Epoch 44/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3292 - accuracy: 0.8462 - val_loss: 0.4880 - val_accuracy: 0.7622\n",
      "Epoch 45/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3280 - accuracy: 0.8449 - val_loss: 0.6276 - val_accuracy: 0.7596\n",
      "Epoch 46/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3292 - accuracy: 0.8467 - val_loss: 0.4756 - val_accuracy: 0.7622\n",
      "Epoch 47/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3286 - accuracy: 0.8450 - val_loss: 0.4926 - val_accuracy: 0.7622\n",
      "Epoch 48/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3283 - accuracy: 0.8453 - val_loss: 0.4615 - val_accuracy: 0.7740\n",
      "Epoch 49/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3278 - accuracy: 0.8464 - val_loss: 0.4926 - val_accuracy: 0.7622\n",
      "Epoch 50/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3295 - accuracy: 0.8451 - val_loss: 0.4380 - val_accuracy: 0.7823\n",
      "Epoch 51/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3277 - accuracy: 0.8473 - val_loss: 0.5429 - val_accuracy: 0.7596\n",
      "Epoch 52/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3251 - accuracy: 0.8469 - val_loss: 0.5215 - val_accuracy: 0.7618\n",
      "Epoch 53/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3265 - accuracy: 0.8463 - val_loss: 0.4668 - val_accuracy: 0.7728\n",
      "Epoch 54/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3259 - accuracy: 0.8461 - val_loss: 0.5125 - val_accuracy: 0.7616\n",
      "Epoch 55/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.3280 - accuracy: 0.8470 - val_loss: 0.5248 - val_accuracy: 0.7622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3265 - accuracy: 0.8456 - val_loss: 0.5700 - val_accuracy: 0.7612\n",
      "Epoch 57/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3295 - accuracy: 0.8469 - val_loss: 0.5091 - val_accuracy: 0.7619\n",
      "Epoch 58/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3286 - accuracy: 0.8461 - val_loss: 0.5015 - val_accuracy: 0.7603\n",
      "Epoch 59/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3261 - accuracy: 0.8477 - val_loss: 0.4592 - val_accuracy: 0.7661\n",
      "Epoch 60/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3243 - accuracy: 0.8485 - val_loss: 0.4184 - val_accuracy: 0.7810\n",
      "Epoch 61/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3268 - accuracy: 0.8459 - val_loss: 0.5115 - val_accuracy: 0.7603\n",
      "Epoch 62/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3263 - accuracy: 0.8467 - val_loss: 0.4649 - val_accuracy: 0.7727\n",
      "Epoch 63/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3250 - accuracy: 0.8480 - val_loss: 0.4850 - val_accuracy: 0.7620\n",
      "Epoch 64/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3252 - accuracy: 0.8473 - val_loss: 0.4963 - val_accuracy: 0.7615\n",
      "Epoch 65/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3251 - accuracy: 0.8486 - val_loss: 0.5393 - val_accuracy: 0.7608\n",
      "Epoch 66/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3245 - accuracy: 0.8490 - val_loss: 0.4749 - val_accuracy: 0.7615\n",
      "Epoch 67/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3231 - accuracy: 0.8487 - val_loss: 0.4961 - val_accuracy: 0.7622\n",
      "Epoch 68/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3243 - accuracy: 0.8488 - val_loss: 0.4577 - val_accuracy: 0.7760\n",
      "Epoch 69/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3262 - accuracy: 0.8483 - val_loss: 0.5109 - val_accuracy: 0.7616\n",
      "Epoch 70/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3253 - accuracy: 0.8479 - val_loss: 0.4747 - val_accuracy: 0.7622\n",
      "Epoch 71/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3258 - accuracy: 0.8478 - val_loss: 0.5128 - val_accuracy: 0.7615\n",
      "Epoch 72/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3241 - accuracy: 0.8481 - val_loss: 0.5044 - val_accuracy: 0.7612\n",
      "Epoch 73/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3243 - accuracy: 0.8481 - val_loss: 0.5580 - val_accuracy: 0.7612\n",
      "Epoch 74/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3253 - accuracy: 0.8468 - val_loss: 0.5667 - val_accuracy: 0.7614\n",
      "Epoch 75/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3233 - accuracy: 0.8470 - val_loss: 0.5061 - val_accuracy: 0.7612\n",
      "Epoch 76/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3226 - accuracy: 0.8492 - val_loss: 0.5747 - val_accuracy: 0.7622\n",
      "Epoch 77/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3240 - accuracy: 0.8474 - val_loss: 0.5608 - val_accuracy: 0.7596\n",
      "Epoch 78/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3245 - accuracy: 0.8487 - val_loss: 0.5292 - val_accuracy: 0.7615\n",
      "Epoch 79/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3241 - accuracy: 0.8483 - val_loss: 0.5287 - val_accuracy: 0.7615\n",
      "Epoch 80/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3270 - accuracy: 0.8485 - val_loss: 0.4863 - val_accuracy: 0.7721\n",
      "Epoch 81/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3238 - accuracy: 0.8494 - val_loss: 0.5771 - val_accuracy: 0.7617\n",
      "Epoch 82/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3240 - accuracy: 0.8481 - val_loss: 0.4961 - val_accuracy: 0.7619\n",
      "Epoch 83/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3234 - accuracy: 0.8490 - val_loss: 0.4981 - val_accuracy: 0.7615\n",
      "Epoch 84/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3229 - accuracy: 0.8468 - val_loss: 0.5145 - val_accuracy: 0.7622\n",
      "Epoch 85/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3226 - accuracy: 0.8480 - val_loss: 0.5563 - val_accuracy: 0.7615\n",
      "Epoch 86/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3248 - accuracy: 0.8497 - val_loss: 0.5115 - val_accuracy: 0.7615\n",
      "Epoch 87/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3245 - accuracy: 0.8482 - val_loss: 0.5094 - val_accuracy: 0.7622\n",
      "Epoch 88/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3219 - accuracy: 0.8500 - val_loss: 0.5334 - val_accuracy: 0.7615\n",
      "Epoch 89/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3240 - accuracy: 0.8482 - val_loss: 0.4965 - val_accuracy: 0.7622\n",
      "Epoch 90/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3223 - accuracy: 0.8482 - val_loss: 0.4941 - val_accuracy: 0.7622\n",
      "Epoch 91/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3237 - accuracy: 0.8471 - val_loss: 0.5080 - val_accuracy: 0.7720\n",
      "Epoch 92/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3229 - accuracy: 0.8486 - val_loss: 0.4798 - val_accuracy: 0.7615\n",
      "Epoch 93/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3249 - accuracy: 0.8488 - val_loss: 0.5036 - val_accuracy: 0.7622\n",
      "Epoch 94/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3224 - accuracy: 0.8494 - val_loss: 0.5219 - val_accuracy: 0.7623\n",
      "Epoch 95/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3227 - accuracy: 0.8485 - val_loss: 0.5352 - val_accuracy: 0.7612\n",
      "Epoch 96/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3223 - accuracy: 0.8504 - val_loss: 0.5526 - val_accuracy: 0.7615\n",
      "Epoch 97/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3246 - accuracy: 0.8481 - val_loss: 0.4758 - val_accuracy: 0.7617\n",
      "Epoch 98/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3212 - accuracy: 0.8500 - val_loss: 0.5336 - val_accuracy: 0.7615\n",
      "Epoch 99/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3224 - accuracy: 0.8499 - val_loss: 0.5276 - val_accuracy: 0.7612\n",
      "Epoch 100/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3231 - accuracy: 0.8498 - val_loss: 0.5888 - val_accuracy: 0.7596\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15060/15060 [==============================] - 0s 22us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5887737494065942, 0.7595617771148682]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7595617529880478"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import  metrics\n",
    "metrics.accuracy_score(y_true= y_test, y_pred= model.predict_classes(X_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Do poniższego modelu dodaj\n",
    " \n",
    "```python\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "```\n",
    "\n",
    "w każdej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki:\n",
    "\n",
    "* porównaj krzywe uczenia\n",
    "* narysuj granice decyzyjne (dane są w 2D)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=5)\n",
    "# split into train and test\n",
    "# n_train = 30\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=2)\n",
    "\n",
    "n_train=53\n",
    "X_train, X_test = X[:n_train, :], X[n_train:, :]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "plt.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.7022 - accuracy: 0.5472 - val_loss: 0.7186 - val_accuracy: 0.5532\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.7658 - accuracy: 0.4528 - val_loss: 0.6659 - val_accuracy: 0.7234\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.6543 - accuracy: 0.7170 - val_loss: 0.7750 - val_accuracy: 0.4468\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.7019 - accuracy: 0.5472 - val_loss: 0.7144 - val_accuracy: 0.4468\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.6327 - accuracy: 0.5849 - val_loss: 0.6089 - val_accuracy: 0.7447\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.5949 - accuracy: 0.7925 - val_loss: 0.6053 - val_accuracy: 0.6383\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.5916 - accuracy: 0.6981 - val_loss: 0.5693 - val_accuracy: 0.7234\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.5374 - accuracy: 0.7925 - val_loss: 0.5446 - val_accuracy: 0.7447\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4977 - accuracy: 0.8113 - val_loss: 0.5322 - val_accuracy: 0.7872\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4613 - accuracy: 0.8302 - val_loss: 0.4980 - val_accuracy: 0.7447\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.4108 - accuracy: 0.8491 - val_loss: 0.4916 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.3810 - accuracy: 0.8679 - val_loss: 0.5164 - val_accuracy: 0.7660\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.3759 - accuracy: 0.8302 - val_loss: 0.5282 - val_accuracy: 0.7660\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.3508 - accuracy: 0.8302 - val_loss: 0.5109 - val_accuracy: 0.7660\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.3317 - accuracy: 0.8679 - val_loss: 0.4968 - val_accuracy: 0.7447\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.3222 - accuracy: 0.8491 - val_loss: 0.4904 - val_accuracy: 0.7447\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3207 - accuracy: 0.8679 - val_loss: 0.4886 - val_accuracy: 0.7447\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.3162 - accuracy: 0.8679 - val_loss: 0.4915 - val_accuracy: 0.7660\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.3073 - accuracy: 0.8679 - val_loss: 0.5050 - val_accuracy: 0.7872\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2898 - accuracy: 0.8679 - val_loss: 0.5164 - val_accuracy: 0.7872\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 547us/step - loss: 0.2775 - accuracy: 0.8679 - val_loss: 0.5217 - val_accuracy: 0.7872\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2712 - accuracy: 0.8679 - val_loss: 0.5163 - val_accuracy: 0.7872\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2635 - accuracy: 0.8868 - val_loss: 0.5088 - val_accuracy: 0.7872\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2569 - accuracy: 0.9057 - val_loss: 0.4887 - val_accuracy: 0.8085\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2516 - accuracy: 0.8868 - val_loss: 0.4600 - val_accuracy: 0.8298\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2480 - accuracy: 0.9057 - val_loss: 0.4499 - val_accuracy: 0.8085\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2491 - accuracy: 0.9057 - val_loss: 0.4582 - val_accuracy: 0.8085\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 560us/step - loss: 0.2392 - accuracy: 0.9057 - val_loss: 0.4547 - val_accuracy: 0.8085\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2373 - accuracy: 0.9057 - val_loss: 0.4519 - val_accuracy: 0.8085\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2343 - accuracy: 0.9057 - val_loss: 0.4603 - val_accuracy: 0.8085\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2306 - accuracy: 0.9057 - val_loss: 0.4694 - val_accuracy: 0.8298\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2307 - accuracy: 0.8868 - val_loss: 0.4781 - val_accuracy: 0.8298\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2254 - accuracy: 0.8868 - val_loss: 0.4728 - val_accuracy: 0.8298\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2224 - accuracy: 0.8868 - val_loss: 0.4665 - val_accuracy: 0.8298\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2229 - accuracy: 0.9057 - val_loss: 0.4670 - val_accuracy: 0.8298\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2209 - accuracy: 0.9057 - val_loss: 0.4652 - val_accuracy: 0.8298\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2199 - accuracy: 0.9057 - val_loss: 0.4601 - val_accuracy: 0.8085\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2172 - accuracy: 0.9057 - val_loss: 0.4710 - val_accuracy: 0.8298\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2123 - accuracy: 0.8868 - val_loss: 0.4870 - val_accuracy: 0.8085\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2088 - accuracy: 0.8868 - val_loss: 0.4955 - val_accuracy: 0.8085\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 718us/step - loss: 0.2083 - accuracy: 0.9057 - val_loss: 0.4985 - val_accuracy: 0.8085\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.2083 - accuracy: 0.8868 - val_loss: 0.4898 - val_accuracy: 0.8085\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.2040 - accuracy: 0.8868 - val_loss: 0.4811 - val_accuracy: 0.8298\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2011 - accuracy: 0.8868 - val_loss: 0.4686 - val_accuracy: 0.8298\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2020 - accuracy: 0.9057 - val_loss: 0.4556 - val_accuracy: 0.8298\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2015 - accuracy: 0.9057 - val_loss: 0.4585 - val_accuracy: 0.8298\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1987 - accuracy: 0.9057 - val_loss: 0.4786 - val_accuracy: 0.8298\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1952 - accuracy: 0.9057 - val_loss: 0.4856 - val_accuracy: 0.8085\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1947 - accuracy: 0.9245 - val_loss: 0.4880 - val_accuracy: 0.8085\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1958 - accuracy: 0.9057 - val_loss: 0.4721 - val_accuracy: 0.8298\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1890 - accuracy: 0.9057 - val_loss: 0.4694 - val_accuracy: 0.8298\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1870 - accuracy: 0.9245 - val_loss: 0.4682 - val_accuracy: 0.8298\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1873 - accuracy: 0.9245 - val_loss: 0.4671 - val_accuracy: 0.8298\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1846 - accuracy: 0.9245 - val_loss: 0.4795 - val_accuracy: 0.8298\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1871 - accuracy: 0.9245 - val_loss: 0.4832 - val_accuracy: 0.8298\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1843 - accuracy: 0.9245 - val_loss: 0.4617 - val_accuracy: 0.8298\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1799 - accuracy: 0.9245 - val_loss: 0.4560 - val_accuracy: 0.8298\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1775 - accuracy: 0.9245 - val_loss: 0.4648 - val_accuracy: 0.8298\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1761 - accuracy: 0.9245 - val_loss: 0.4666 - val_accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1736 - accuracy: 0.9434 - val_loss: 0.4531 - val_accuracy: 0.8298\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1707 - accuracy: 0.9245 - val_loss: 0.4472 - val_accuracy: 0.8298\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1701 - accuracy: 0.9245 - val_loss: 0.4366 - val_accuracy: 0.8298\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 547us/step - loss: 0.1671 - accuracy: 0.9434 - val_loss: 0.4266 - val_accuracy: 0.8298\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1687 - accuracy: 0.9245 - val_loss: 0.4142 - val_accuracy: 0.8298\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1641 - accuracy: 0.9245 - val_loss: 0.4202 - val_accuracy: 0.8298\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1622 - accuracy: 0.9434 - val_loss: 0.4305 - val_accuracy: 0.8298\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1618 - accuracy: 0.9434 - val_loss: 0.4368 - val_accuracy: 0.8298\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1583 - accuracy: 0.9811 - val_loss: 0.4477 - val_accuracy: 0.8298\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1587 - accuracy: 0.9623 - val_loss: 0.4452 - val_accuracy: 0.8298\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.1553 - accuracy: 0.9623 - val_loss: 0.4396 - val_accuracy: 0.8298\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.1586 - accuracy: 0.9623 - val_loss: 0.4179 - val_accuracy: 0.8298\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1490 - accuracy: 0.9623 - val_loss: 0.4184 - val_accuracy: 0.8298\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1476 - accuracy: 0.9623 - val_loss: 0.4166 - val_accuracy: 0.8298\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1453 - accuracy: 0.9623 - val_loss: 0.4063 - val_accuracy: 0.8298\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1436 - accuracy: 0.9623 - val_loss: 0.3879 - val_accuracy: 0.8511\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1413 - accuracy: 0.9623 - val_loss: 0.3849 - val_accuracy: 0.8511\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1388 - accuracy: 0.9623 - val_loss: 0.3778 - val_accuracy: 0.8511\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1359 - accuracy: 0.9623 - val_loss: 0.3790 - val_accuracy: 0.8511\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1329 - accuracy: 0.9623 - val_loss: 0.3877 - val_accuracy: 0.8723\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1333 - accuracy: 0.9811 - val_loss: 0.3839 - val_accuracy: 0.8723\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1301 - accuracy: 0.9811 - val_loss: 0.3897 - val_accuracy: 0.8723\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1277 - accuracy: 0.9811 - val_loss: 0.3758 - val_accuracy: 0.8723\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1231 - accuracy: 0.9811 - val_loss: 0.3533 - val_accuracy: 0.8511\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1212 - accuracy: 0.9623 - val_loss: 0.3281 - val_accuracy: 0.8511\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1221 - accuracy: 0.9434 - val_loss: 0.3199 - val_accuracy: 0.8511\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1199 - accuracy: 0.9434 - val_loss: 0.3244 - val_accuracy: 0.8511\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1130 - accuracy: 0.9811 - val_loss: 0.3316 - val_accuracy: 0.8723\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1105 - accuracy: 0.9811 - val_loss: 0.3405 - val_accuracy: 0.8936\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1105 - accuracy: 0.9811 - val_loss: 0.3401 - val_accuracy: 0.8936\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1114 - accuracy: 0.9811 - val_loss: 0.3306 - val_accuracy: 0.8936\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1049 - accuracy: 0.9811 - val_loss: 0.2951 - val_accuracy: 0.8723\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1002 - accuracy: 0.9811 - val_loss: 0.2759 - val_accuracy: 0.8511\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1025 - accuracy: 0.9623 - val_loss: 0.2697 - val_accuracy: 0.8511\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0990 - accuracy: 0.9623 - val_loss: 0.2852 - val_accuracy: 0.8723\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 528us/step - loss: 0.0926 - accuracy: 0.9811 - val_loss: 0.3001 - val_accuracy: 0.8936\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0910 - accuracy: 0.9811 - val_loss: 0.3121 - val_accuracy: 0.8936\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0911 - accuracy: 0.9811 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0895 - accuracy: 0.9811 - val_loss: 0.2827 - val_accuracy: 0.8723\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0861 - accuracy: 0.9811 - val_loss: 0.2661 - val_accuracy: 0.8723\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0835 - accuracy: 0.9811 - val_loss: 0.2373 - val_accuracy: 0.8936\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0827 - accuracy: 0.9811 - val_loss: 0.2289 - val_accuracy: 0.8936\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0813 - accuracy: 0.9811 - val_loss: 0.2371 - val_accuracy: 0.9149\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0740 - accuracy: 0.9811 - val_loss: 0.2381 - val_accuracy: 0.9149\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0718 - accuracy: 0.9811 - val_loss: 0.2366 - val_accuracy: 0.9149\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0708 - accuracy: 0.9811 - val_loss: 0.2377 - val_accuracy: 0.9149\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0674 - accuracy: 0.9811 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 566us/step - loss: 0.0654 - accuracy: 0.9811 - val_loss: 0.2047 - val_accuracy: 0.9149\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.8936\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.8936\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.8936\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9149\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9149\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9149\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9149\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9149\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9149\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9362\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9362\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9149\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9149\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9149\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9149\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9149\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9149\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9149\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9362\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9362\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9362\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9362\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9362\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9362\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9149\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9362\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9362\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9362\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9362\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9362\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9149\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.8936\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9149\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9149\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9362\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9149\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9362\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9149\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.8936\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.8936\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.8936\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9149\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9362\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9362\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9149\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9149\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9362\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9149\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9149\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.8936\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.8936\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9149\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9149\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9149\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9149\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9149\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.8936\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.8936\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9149\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9149\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9362\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 567us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9149\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9149\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9149\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.8936\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.8936\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9149\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9149\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9149\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9149\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9149\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9149\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9149\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.8936\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9149\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9149\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.8936\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.8936\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9362\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.8936\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.8936\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9149\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9149\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9149\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.8936\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9149\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.8936\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9149\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9149\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9149\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9149\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9149\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.8936\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9149\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9149\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9149\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9149\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9149\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9149\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.8936\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.8936\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.8936\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.8936\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.8936\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9149\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9149\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.8936\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9149\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.8936\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9149\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9149\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 548us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9149\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9149\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9149\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9149\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9149\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9149\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9149\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 522us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9149\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9149\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9149\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9149\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9149\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 599us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9149\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9149\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9149\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9149\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9149\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9149\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.8936\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9149\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.8936\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9149\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9149\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9149\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9149\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9149\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9149\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9149\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9149\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9149\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9149\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9149\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9149\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9149\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9149\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9149\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9149\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9149\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9149\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9149\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9149\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9149\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9149\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9149\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9149\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9149\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9149\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9149\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9149\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9149\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9149\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9149\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9149\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9149\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9149\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9149\n",
      "Epoch 275/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9149\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9149\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9149\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9149\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9149\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9149\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9149\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9149\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9149\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9149\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9149\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9149\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9149\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9149\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9149\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9149\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9149\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9149\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9149\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9149\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9149\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9149\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9149\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9149\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9149\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9149\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9149\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9149\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9149\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9149\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9149\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9149\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9149\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9149\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9149\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9149\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 532us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9149\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9149\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9149\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9149\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9149\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9149\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9149\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9149\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9149\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 529us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9149\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9149\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9149\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9149\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9149\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9149\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9149\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9149\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9149\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9149\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9149\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9149\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9149\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9149\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9149\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9149\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9149\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9149\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9149\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9149\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9149\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9149\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9149\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9149\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9149\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9149\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9149\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9149\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9149\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9149\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9149\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9149\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9149\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9149\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9149\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9149\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9149\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9149\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9149\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9149\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9149\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9149\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9149\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9149\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9149\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9149\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9149\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9149\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9149\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9149\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9149\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9149\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9149\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9149\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9149\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9149\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9149\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.9149\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9149\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9149\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9149\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 228us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9149\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9149\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9149\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9149\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9149\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 618us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9149\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9149\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 661us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9149\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9149\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9149\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9149\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9149\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9149\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9149\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9149\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9149\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9149\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9149\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9149\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9149\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9149\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9149\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9149\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9149\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9149\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9149\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9149\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9149\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9149\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9149\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9149\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9149\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9149\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9149\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9149\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9149\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9149\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9149\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9149\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9149\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9149\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9149\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9149\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9149\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9149\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9149\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9149\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9149\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9149\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9149\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9149\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9149\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9149\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9149\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9149\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9149\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9149\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.9149\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9149\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9149\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9149\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9149\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9149\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9149\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9149\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9149\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9149\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9149\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9149\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9149\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9149\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9149\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9149\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9149\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 273us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9149\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 760us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9149\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9149\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9149\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9149\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9149\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 9.9935e-04 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9149\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9149\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 9.8451e-04 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9149\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9149\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 9.7640e-04 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9149\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 9.6916e-04 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9149\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9149\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 9.6911e-04 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9149\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 9.5477e-04 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9149\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 9.5174e-04 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9149\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 9.7198e-04 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 9.5533e-04 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9149\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 9.4799e-04 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9149\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 9.4707e-04 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9149\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 9.5402e-04 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9149\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9149\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 9.9512e-04 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9149\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 9.5823e-04 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9149\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 9.0663e-04 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9149\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 9.2703e-04 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9149\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 9.3644e-04 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9149\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 246us/step - loss: 8.9341e-04 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9149\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 804us/step - loss: 8.8749e-04 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9149\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 8.8237e-04 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9149\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 8.7890e-04 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9149\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 9.0034e-04 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9149\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 8.6864e-04 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9149\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 9.0364e-04 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9149\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.8243e-04 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9149\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 8.5585e-04 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9149\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.4070e-04 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9149\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.6181e-04 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9149\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.9438e-04 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9149\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 9.0023e-04 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 8.8346e-04 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9149\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 8.4472e-04 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9149\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 8.2097e-04 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9149\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 8.2142e-04 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9149\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 8.4348e-04 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9149\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 8.6371e-04 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9149\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.7755e-04 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9149\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.1509e-04 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9149\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.8309e-04 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9149\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.1709e-04 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.9149\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.4009e-04 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.9149\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.3579e-04 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.9149\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.2287e-04 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9149\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.9868e-04 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9149\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.0890e-04 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9149\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.7480e-04 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9149\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.7211e-04 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.9149\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.4368e-04 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9149\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.2166e-04 - accuracy: 1.0000 - val_loss: 0.3020 - val_accuracy: 0.9149\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.8637e-04 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9149\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.1226e-04 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9149\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.7167e-04 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9149\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.0169e-04 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9149\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.6816e-04 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9149\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 7.8205e-04 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9149\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 7.5075e-04 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9149\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 7.6915e-04 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9149\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 7.3683e-04 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9149\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 7.3012e-04 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9149\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 7.3328e-04 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.9149\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 7.2104e-04 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9149\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 7.2723e-04 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9149\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 7.2948e-04 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9149\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.2740e-04 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.9149\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.1798e-04 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.9149\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.0794e-04 - accuracy: 1.0000 - val_loss: 0.3057 - val_accuracy: 0.9149\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.0170e-04 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9149\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.2554e-04 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9149\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.0886e-04 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9149\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.3102e-04 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.9149\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.9147e-04 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.9149\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.0291e-04 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.9149\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.9436e-04 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9149\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.1659e-04 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9149\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.9814e-04 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9149\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.7892e-04 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9149\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.1195e-04 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.9149\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 6.7755e-04 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.9149\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.8506e-04 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9149\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.6039e-04 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.9149\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.0717e-04 - accuracy: 1.0000 - val_loss: 0.3101 - val_accuracy: 0.9149\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.6672e-04 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.9149\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 6.8302e-04 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9149\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.5581e-04 - accuracy: 1.0000 - val_loss: 0.3114 - val_accuracy: 0.9149\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 6.4705e-04 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9149\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 6.9497e-04 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9149\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 6.6646e-04 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9149\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 6.6408e-04 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9149\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.3211e-04 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9149\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 6.8182e-04 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.8936\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 6.4333e-04 - accuracy: 1.0000 - val_loss: 0.3127 - val_accuracy: 0.8936\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 6.4693e-04 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.8936\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 6.5260e-04 - accuracy: 1.0000 - val_loss: 0.3139 - val_accuracy: 0.8936\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 6.2374e-04 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.8936\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 6.1066e-04 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9149\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.1816e-04 - accuracy: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.9149\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.7512e-04 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9149\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.4693e-04 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9149\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.2448e-04 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9149\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 6.0809e-04 - accuracy: 1.0000 - val_loss: 0.3174 - val_accuracy: 0.8936\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.3499e-04 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.8936\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.0580e-04 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.8936\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.9916e-04 - accuracy: 1.0000 - val_loss: 0.3176 - val_accuracy: 0.8936\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.9616e-04 - accuracy: 1.0000 - val_loss: 0.3185 - val_accuracy: 0.8936\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 6.1341e-04 - accuracy: 1.0000 - val_loss: 0.3194 - val_accuracy: 0.8936\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 5.9066e-04 - accuracy: 1.0000 - val_loss: 0.3194 - val_accuracy: 0.8936\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.0794e-04 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.8936\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.8429e-04 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.8936\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.8067e-04 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.8936\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 5.7819e-04 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.8936\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 5.8930e-04 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.8936\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.7696e-04 - accuracy: 1.0000 - val_loss: 0.3216 - val_accuracy: 0.8936\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.6787e-04 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.8936\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 5.6783e-04 - accuracy: 1.0000 - val_loss: 0.3213 - val_accuracy: 0.8936\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.7934e-04 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.8936\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.9551e-04 - accuracy: 1.0000 - val_loss: 0.3216 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 6.0724e-04 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.8936\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 5.7589e-04 - accuracy: 1.0000 - val_loss: 0.3231 - val_accuracy: 0.8936\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.6197e-04 - accuracy: 1.0000 - val_loss: 0.3251 - val_accuracy: 0.8936\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.5657e-04 - accuracy: 1.0000 - val_loss: 0.3267 - val_accuracy: 0.8936\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 5.7090e-04 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.8936\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 6.0892e-04 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.8936\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 6.0360e-04 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.8936\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.5283e-04 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.8936\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.4032e-04 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.8936\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.4092e-04 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.8936\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.4141e-04 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.8936\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.4683e-04 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.8936\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.4735e-04 - accuracy: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.8936\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 5.4119e-04 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.8936\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.5073e-04 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.8936\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 5.2672e-04 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.8936\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 5.3287e-04 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.8936\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.4278e-04 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.8936\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.3249e-04 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.8936\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.1986e-04 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.8936\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.1794e-04 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.8936\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.1544e-04 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.8936\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.2214e-04 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.8936\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 5.2271e-04 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.8936\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.2385e-04 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.8936\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 5.1967e-04 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.8936\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 5.2016e-04 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.8936\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 5.1980e-04 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.8936\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.0758e-04 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.8936\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.9831e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.8936\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.2595e-04 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 0.8936\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.1478e-04 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 0.8936\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 4.9410e-04 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.8936\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.9151e-04 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.8936\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.9297e-04 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.8936\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 5.0393e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.8936\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 5.1665e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.8936\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 5.0975e-04 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 0.8936\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.9399e-04 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.8936\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 4.8829e-04 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.8936\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.8116e-04 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.8936\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.7761e-04 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.8936\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.7285e-04 - accuracy: 1.0000 - val_loss: 0.3407 - val_accuracy: 0.8936\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.7506e-04 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.8936\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.8296e-04 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.8936\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.7746e-04 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.8936\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.7743e-04 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.8936\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.7252e-04 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.8936\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.6446e-04 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.8936\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.7894e-04 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.8936\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.5925e-04 - accuracy: 1.0000 - val_loss: 0.3421 - val_accuracy: 0.8936\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 4.6797e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.8936\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 547us/step - loss: 4.5621e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.8936\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 493us/step - loss: 4.5499e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.8936\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 562us/step - loss: 4.5387e-04 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.8936\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.5165e-04 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.8936\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 464us/step - loss: 4.5005e-04 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.8936\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 605us/step - loss: 4.4768e-04 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.8936\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.4518e-04 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.8936\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 255us/step - loss: 4.4427e-04 - accuracy: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.8936\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 4.5206e-04 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.8936\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.4131e-04 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.8936\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.4221e-04 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.8936\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 655us/step - loss: 4.3844e-04 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.8936\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.4007e-04 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.8936\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.3904e-04 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.8936\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 399us/step - loss: 4.3423e-04 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.8936\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.4437e-04 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.8936\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 4.2884e-04 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.8936\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 559us/step - loss: 4.2712e-04 - accuracy: 1.0000 - val_loss: 0.3485 - val_accuracy: 0.8936\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 4.3401e-04 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.8936\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.2737e-04 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.8936\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 4.2247e-04 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.8936\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.4049e-04 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.8936\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.2410e-04 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.8936\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.2146e-04 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.8936\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.1676e-04 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.8936\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.1397e-04 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.8936\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.1813e-04 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.8936\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.2399e-04 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.8936\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.3150e-04 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.8936\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.1940e-04 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.8936\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.2804e-04 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.8936\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.0759e-04 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.8936\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.0818e-04 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.8936\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.0266e-04 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.8936\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.0154e-04 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.8936\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.1661e-04 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.8936\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.0422e-04 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.8936\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 5.4406e-05 - accuracy: 1.00 - 0s 529us/step - loss: 3.9695e-04 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.8936\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.9488e-04 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.8936\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.9605e-04 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.8936\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.9473e-04 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.8936\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.9950e-04 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.8936\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.9647e-04 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.8936\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.9294e-04 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.8936\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 3.9936e-04 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.8936\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.9047e-04 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.8936\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.9602e-04 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.8936\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.8403e-04 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.8936\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.9819e-04 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.8936\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.9059e-04 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.8936\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.7821e-04 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.8936\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.7688e-04 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.8936\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 3.7508e-04 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.8936\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.7434e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.8936\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.7346e-04 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.8936\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.7825e-04 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.8936\n",
      "Epoch 716/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 566us/step - loss: 3.7023e-04 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.8936\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 3.6810e-04 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.8936\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.6947e-04 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.8936\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.7275e-04 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 0.8936\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.8195e-04 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.8936\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.6831e-04 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.8936\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.6392e-04 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.8936\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.5838e-04 - accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.8936\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.7969e-04 - accuracy: 1.0000 - val_loss: 0.3655 - val_accuracy: 0.8936\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.7549e-04 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.8936\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.6542e-04 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.8936\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.5531e-04 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.8936\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.6894e-04 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.8936\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.5432e-04 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.8936\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.5302e-04 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.8936\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.5936e-04 - accuracy: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.8936\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.5761e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.8936\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.5798e-04 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.8936\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.4657e-04 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.8936\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.5163e-04 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.8936\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.4425e-04 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.8936\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.4336e-04 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.8936\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.4279e-04 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.8936\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.4192e-04 - accuracy: 1.0000 - val_loss: 0.3700 - val_accuracy: 0.8936\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.3927e-04 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.8936\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.4206e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.8936\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.4900e-04 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.8936\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.4185e-04 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.8936\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.3506e-04 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.8936\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.3888e-04 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.8936\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.4391e-04 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.8936\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.3413e-04 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.8936\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.4006e-04 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.8936\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.2874e-04 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 0.8936\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.3330e-04 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.8936\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.3604e-04 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.8936\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 4.6984e-04 - accuracy: 1.00 - 0s 529us/step - loss: 3.2554e-04 - accuracy: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.8936\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.2390e-04 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.8936\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.2323e-04 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.8936\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.2662e-04 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.8936\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.2186e-04 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.8936\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.2019e-04 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.8936\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.2224e-04 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.8936\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.2230e-04 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.8936\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.2663e-04 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.8936\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.2389e-04 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.8936\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.1529e-04 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.8936\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.1380e-04 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.8936\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.1320e-04 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.8936\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.1283e-04 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.8936\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.2259e-04 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.8936\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 524us/step - loss: 3.1204e-04 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.8936\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0953e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.8936\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 567us/step - loss: 3.0705e-04 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.8936\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.1604e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.8936\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.1086e-04 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.8936\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.0516e-04 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.8936\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.0218e-04 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.8936\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.0200e-04 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.8936\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.1644e-04 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.8936\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 3.0671e-04 - accuracy: 1.0000 - val_loss: 0.3824 - val_accuracy: 0.8936\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 3.0228e-04 - accuracy: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.8936\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.9915e-04 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.8936\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 3.0984e-04 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.8936\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 2.9700e-04 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.8936\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.9659e-04 - accuracy: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.8936\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.0152e-04 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.8936\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 3.0004e-04 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.8936\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 2.9434e-04 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.8936\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.0253e-04 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.8936\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.9325e-04 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.8936\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.9932e-04 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.8936\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.9065e-04 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.8936\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.8847e-04 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.8936\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.8585e-04 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.8936\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.9192e-04 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.8936\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.8432e-04 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.8936\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.8870e-04 - accuracy: 1.0000 - val_loss: 0.3882 - val_accuracy: 0.8936\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.8469e-04 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.8936\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.9109e-04 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.8936\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.8586e-04 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.8936\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.8890e-04 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.8936\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.7819e-04 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.8936\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.8186e-04 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.8936\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.7778e-04 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.8936\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.7548e-04 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.8936\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.7609e-04 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.8936\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.7836e-04 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.8936\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.7949e-04 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.8936\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 2.8303e-04 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.8936\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.7893e-04 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.8936\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.7839e-04 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.8936\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.7097e-04 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.8936\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.6901e-04 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.8936\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.6789e-04 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.8936\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.7800e-04 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.8936\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.7416e-04 - accuracy: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.8936\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.6725e-04 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.8936\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.6610e-04 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.8936\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.6757e-04 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.8936\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.6227e-04 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.8936\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.5905e-04 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.8936\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.5919e-04 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.8936\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.7948e-04 - accuracy: 1.0000 - val_loss: 0.3974 - val_accuracy: 0.8936\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.7116e-04 - accuracy: 1.0000 - val_loss: 0.3977 - val_accuracy: 0.8936\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 2.7314e-04 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.8936\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 2.6735e-04 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.8936\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.6313e-04 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.8936\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.5693e-04 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.5626e-04 - accuracy: 1.0000 - val_loss: 0.3995 - val_accuracy: 0.8936\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.5963e-04 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.8936\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.5405e-04 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.8936\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.5676e-04 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.8936\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.5927e-04 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.8936\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.5278e-04 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.8936\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.5667e-04 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.8936\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.5419e-04 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.8936\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.5084e-04 - accuracy: 1.0000 - val_loss: 0.4014 - val_accuracy: 0.8936\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.4846e-04 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.8936\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.4849e-04 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.8936\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.5561e-04 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.8936\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 2.4963e-04 - accuracy: 1.0000 - val_loss: 0.4026 - val_accuracy: 0.8936\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.5296e-04 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.8936\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 2.4484e-04 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.8936\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 2.4401e-04 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.8936\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 2.4800e-04 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.8936\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 719us/step - loss: 2.4276e-04 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.8936\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 2.4744e-04 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.8936\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 2.4152e-04 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.8936\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.4567e-04 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.8936\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.3982e-04 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.8936\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.3912e-04 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.8936\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.4330e-04 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.8936\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.3805e-04 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.8936\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.4285e-04 - accuracy: 1.0000 - val_loss: 0.4050 - val_accuracy: 0.8936\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.3634e-04 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.8936\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.3828e-04 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.8936\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.4222e-04 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.8936\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.3477e-04 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.8936\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.3366e-04 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.8936\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.3571e-04 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.8936\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.3934e-04 - accuracy: 1.0000 - val_loss: 0.4068 - val_accuracy: 0.8936\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.3170e-04 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.8936\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.3442e-04 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.8936\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.3650e-04 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.8936\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.2920e-04 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.8936\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.2880e-04 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.8936\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.3108e-04 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.8936\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.2700e-04 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.8936\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.2806e-04 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.8936\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.2636e-04 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.8936\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.2609e-04 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.8936\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.2832e-04 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.8936\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.3111e-04 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8936\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.2874e-04 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.8936\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.2949e-04 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.8936\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.2961e-04 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.8936\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.2175e-04 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.8936\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.2027e-04 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.8936\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.2487e-04 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.8936\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.2166e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.8936\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.1861e-04 - accuracy: 1.0000 - val_loss: 0.4125 - val_accuracy: 0.8936\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.1677e-04 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.8936\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.1675e-04 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.8936\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.1879e-04 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.8936\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.2171e-04 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.8936\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.2444e-04 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.8936\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.2437e-04 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.8936\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.2721e-04 - accuracy: 1.0000 - val_loss: 0.4140 - val_accuracy: 0.8936\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.1972e-04 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.8936\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.2292e-04 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.8936\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.1450e-04 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.8936\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.1207e-04 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.8936\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.1094e-04 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.8936\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.1683e-04 - accuracy: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.8936\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.1149e-04 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.8936\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.0999e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.8936\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.0969e-04 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.8936\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.1436e-04 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.8936\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.0721e-04 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.8936\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.0671e-04 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.8936\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.0856e-04 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.8936\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.1099e-04 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.8936\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.0817e-04 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.8936\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.0844e-04 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.8936\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.0323e-04 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.8936\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.0241e-04 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.8936\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.0208e-04 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.8936\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.0148e-04 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.8936\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.0091e-04 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.8936\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.0011e-04 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.8936\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.9978e-04 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.8936\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.9897e-04 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.8936\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.0194e-04 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.8936\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.9779e-04 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.8936\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.9884e-04 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.8936\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.9714e-04 - accuracy: 1.0000 - val_loss: 0.4222 - val_accuracy: 0.8936\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.9724e-04 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.8936\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.9711e-04 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.8936\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.9617e-04 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.8936\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.9556e-04 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.8936\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.9436e-04 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.8936\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.9478e-04 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.8936\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.9870e-04 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.8723\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.9305e-04 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.8723\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.9511e-04 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.8723\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.9663e-04 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.8936\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.9088e-04 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.8936\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.9014e-04 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.8936\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.9229e-04 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.8723\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.9004e-04 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.8936\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.8875e-04 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.8936\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.9575e-04 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.8936\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.9238e-04 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.8936\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.8930e-04 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.8936\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 1.8838e-04 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.8936\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 1.8742e-04 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.8936\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 1.8599e-04 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.8723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 1.8500e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.8723\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 1.8460e-04 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.8723\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 1.8437e-04 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.8723\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.8733e-04 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.8723\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.8389e-04 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.8723\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.8335e-04 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.8723\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.8194e-04 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.8723\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.8202e-04 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.8723\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.8228e-04 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.8723\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.8551e-04 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.8936\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.8140e-04 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.8723\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.8026e-04 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.8723\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.7930e-04 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.8723\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.7956e-04 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.8723\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.7992e-04 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.8723\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.8365e-04 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.8723\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.7987e-04 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.8723\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.8226e-04 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.8723\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.7788e-04 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.8723\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.8074e-04 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.8723\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.7571e-04 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.8723\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 1.7522e-04 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.8723\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 1.7689e-04 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.8723\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 1.7867e-04 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.8723\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 1.7356e-04 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.8723\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 1.7300e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.8723\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.7270e-04 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.8723\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.7221e-04 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.8723\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 1.7420e-04 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.8723\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 1.7245e-04 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.8723\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 747us/step - loss: 1.7084e-04 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.8723\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 1.7089e-04 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.8723\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 670us/step - loss: 1.7210e-04 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.8723\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 541us/step - loss: 1.7095e-04 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.8723\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.7331e-04 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.8723\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.7013e-04 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.8723\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.6819e-04 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.8723\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 1.7325e-04 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.8723\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6825e-04 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.8723\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6976e-04 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.8723\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 1.7055e-04 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.8723\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.6724e-04 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.8723\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.6942e-04 - accuracy: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.8723\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.6491e-04 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.8723\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.6730e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.8723\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6521e-04 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.8723\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6365e-04 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.8723\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.6364e-04 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.8723\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6680e-04 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.8723\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.6429e-04 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.8723\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6259e-04 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.8723\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.6155e-04 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.8723\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6166e-04 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.8723\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.6125e-04 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.8723\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.6199e-04 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.8723\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.6377e-04 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.8723\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6288e-04 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.8723\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6540e-04 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.8723\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.6136e-04 - accuracy: 1.0000 - val_loss: 0.4416 - val_accuracy: 0.8723\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.5982e-04 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.8723\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.5784e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.8723\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.5762e-04 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.8723\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.5886e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.8723\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6012e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.8723\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.6059e-04 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.8723\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.5976e-04 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.8723\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.6120e-04 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x48bbca7390>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(500,activation=\"sigmoid\"))\n",
    "model.add(Dense(200,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3xUVfrH8c+TQktIAEMzIDUi0osoFkBQKYIsKggW1FVxEXDXsq5l1V3X3WVlZX8oCAIqFqSoIEiRsopRkS69iREhJhACJCQEAsmc3x9J3ACTOnfuvZN53q8XLzIzl3uegfCdk3PPPUeMMSillKr4QpwuQCmllD008JVSKkho4CulVJDQwFdKqSChga+UUkEizOkCivPl7hSdQqSUUmVw/WV1pKjXXB34+1IynS5BKaUCyvWX1SnyNR3SUUqpIKGBr5RSQcLnwBeRhiLypYjsEpEdIvJ7L8eIiLwmIvtEZKuIdPS1XaWUUmVjxRh+DvCEMWaTiFQHNorICmPMzkLH9AXi8n9dCUzO/10ppVxHMESHe6gSCiJFXgN1jDGG07mQfjYEQ+nr8znwjTHJQHL+1xkisguIBQoH/kDgPZO3cM8aEakhIvXz/6xSSrlKdLiHGhFV8EgYuDDwMYYqJgdOnibtbGip/5ilY/gi0hjoAKw976VY4GChx4n5z3k7xwgR2SAiG+IXzrKyPKWUKpUqobg37AFE8EgYVUqf9YCF0zJFJBL4BPiDMebE+S97+SNe59gbY6YCUwGmxSfoPHyllO1ExL1hX0CkzMNNlvTwRSScvLCfaYyZ5+WQRKBhoccNgCQr2lZKKVU6VszSEeAtYJcxZnwRhy0EhufP1rkKSNfxe6WUKt6Gb77ggQHXcn+/rsyZ/rrP57NiSOca4B5gm4hszn/uWeASAGPMFGAJ0A/YB2QB91vQrlJKVVi5ublM+vuz/GPqHGLq1efRoX256vqbaNSsRbnPacUsnW/wPkZf+BgDjPK1LaWUcpvfDx9E+onzL1tCdFQUE96bX+7z7tn2PfUvaUz9ho0A6N53IN99uczZwFdKqWCWfuIEcSMmXvD8D1NH+3TeoymHqF3vf5MZY+rWZ8/W7306py6toJRSLuRtv3FfbwLTwFdKKReKqVufI4d++fVx6uFkatWp69M5NfCVUsqFWrRuT9LPP3Eo8QBnz57hq6ULuKpHb5/OqWP4SinlQqFhYTzy7D947nfD8OTmctOgoTRuXv4LtqCBr5RSPomOivJ6gTY6Ksrnc3fp1osu3Xr5fJ4CGvhKKeUDX6Ze2k3H8JVSKkho4CulVJDQwFdKqSChga+UUkFCA18ppYKEBr5SSrnQ+Ocf447urXl4UA/LzqmBr5RSLnTjwCG8PPlDS8+pga+UUhZIP36Uvz96NyfSjllyvjadu1I9uqYl5yqgga+UUhb44tOZeJK28N/5HzhdSpE08JVSykfpx4/y/YqP+b9bG/D9io8t6+VbTQNfKaV89MWnMxnQHOLqVmVAcxzp5WemH+fb918p9hgNfKWU8kFB7/7OTtEA3Nkp2tZefvbpU6z75A2SF47l34MaFXusJYEvIm+LSIqIbC/i9R4iki4im/N/vWBFu0op5bSC3v1FkeFA3u9W9PL/+dRIHru7P4n7f+TuXh35fN65M3Y8ubkc3LGW3TOf57lukbxyfzdiakQWe07xto1WWYlINyATeM8Y09rL6z2AJ40x/cty3mnxCb4Xp5RSZVS/qofwqsWHZ4GXRg4mLfnnC56vUb8RL0z+yOrSMBgSd24k68AWerSKpW10xrkHXD2myH0QLVke2RgTLyKNrTiXUkoFEn+EelEO799D6s7VXN8yhg43tyUtKweyM0r+g/nsHMPvKiJbRGSpiLQq6iARGSEiG0RkQ/zCWTaWp5RS7nTsUCI7Pn+XRlnbeax/azo0r1eu89i1AcomoJExJlNE+gGfAnHeDjTGTAWmgg7pKKWcYYwBY0CKHB2xRUb6MQ6uX0ZcTWFwn8sIC/1fHz1vNL5sEWlL4BtjThT6eomIvCEiMcaYVDvaV0qpsjidC1VMDh7CHAn901kn+WndMuqFn+R3PZpRtXL4Oa8bA9kmlNCc0g/ngE2BLyL1gMPGGCMiXcgbSjpqR9tKKVVW6WdD4ORpqoSC2Bj4uTlnObDtOyLOHOX2dg2IrFaf7FzIzso570hDaE4GEbllm/ppSeCLyCygBxAjIonAi0A4gDFmCnA7MFJEcoBTwFBjxfQgpZTyA4OQdjYUztrTXm5ODltXfoQkbuSJAW1oGhsDpEK2te1YMi3TX3QMXylVkRlj2L36c9K2rmRU7xZ0ujTW95P6e1qmUkqpstm/fS0Hvv6Ye65uyE1jetrSpga+UkrZKHn/Hn5Y9i59Wkbxt1HdCAmxb3a8Br5SStngeEoy2xdNo1MdD2+NuJJK4fbHrwa+Ukr50cmMdLZ8Np3GoUeZdFcnqkdUcawWDXyllPKDs9nZfL94BtGZCfxrUAfq1LzM6ZI08JVSykqe3Fy2/fdjcn9ez1MDWhPXoJvTJf1KA18ppSxgjGH3muUc37yckTfE0aXf9U6XdAENfKWU8tH+7Rs48PUchl0ZSz+bpliWhwa+UkqV06H9P7B32Tvc2KK67VMsy0MDXymlyuj4kUNs/2wqHWs7N8WyPAKjSqWUcoGsjBNs/myaK6ZYlocGvlJKleBM9mk2L36X6IwfGTuoA3VrOT/Fsjw08JVSqgie3Fy2rpyLObiRp/q3Jq5Bd6dL8okGvlJKnccYw57vlnF8ywoeuakFnW923xTL8tDAV0Hjn6OHkZl54Q5BkZHVeWai7p+s8uzfvpYD8R9x99UN6e3iKZbloYGvgkZmZgZNH3z9gucTpo9xoBrlNkkJu/lhxbv0a1mDv43u7vopluWhga+UCmpHDyexc/E0rqgL7zzclfCwUKdL8hsNfKVUUMpMP87Wz6bTtHIab9zdichqlZ0uye808JVSQSX7VBabF8+g1qmfGTeoIzE1Lne6JNto4CulgkJuTg5bln9IaPJW/nxLWxrXd88qlnaxJPBF5G2gP5BijGnt5XUBJgD9gCzgPmPMJivaVqq0IiOre71AGxlZXWfwVGDGGHZ8vYiTu1YxuvdltL+lYkyxLA+revgzgInAe0W83heIy/91JTA5/3elbFNccD93X3+dwVMB7dv0NYfWLuC+6xpz/aiKNcWyPCwJfGNMvIg0LuaQgcB7xhgDrBGRGiJS3xiTbEX7SilVWOLebSR88QED29bmttE9yBtkUHZNNI0FDhZ6nJj/3AVEZISIbBCRDfEL9UdppVTpHUn8ifhpz9Pg5wXMGHktt3drqWFfiF0Xbb39jRtvBxpjpgJTAabFJ3g9RrmHjn0rN0hLPcz2RdNoU/MM037biSqVw50uyZXsCvxEoGGhxw2AJJvaVn6kd68qJ53MSGfzwmk0CTvGa0M7Eh1Z1emSXM2uwF8IjBaR2eRdrE3X8XvlJsXN4FHuk30qiy1LZlAz62f+NbA9dWu1dLqkgGDVtMxZQA8gRkQSgReBcABjzBRgCXlTMveRNy3zfivaVcoqOvwUGHLOnmHLsg8JT9nBcwPaBOVcel9YNUtnWAmvG2CUFW0p5U96TcKdPB4P27+cT/aPqxnT53LaNO3hdEkBSe+0VUHLW7gfT00h9q5/Uq9h03Oe12sSzjDGsGfNCo5tXs5DPZtxdW+dS+8LDXzlk0Ae+/Z2wXnrxJHk5uY6VJEqLGHLd/zy7TzuuDKWfjqX3hIa+EHEH8MVVg5zuGk45dDBhHOC/3hqCs/d11+HdmxQcNPUza0u4h9jumvQW0gDP4i4fQqlm+rLzc2lcswlvz4Oj6xF0wdfd83fVUV0+GACez5/h26NK/PCyGsJDa14G5A4TQNfKeWovA1IptOhdi7TH+hE5Up605S/aOArVUholWocmv1nIK9XX/h5Za0Tx1PZvmg6zapmBM0GJE7TwFdBy9sF56pA7cbNihxeUr7Lysxg82fTqW8O8+ptHakVFXHBMalpmTw89gOmPnMPF0Vf+LoqHw18FbRKWi5ZWSv79Ck2L36X6IwE/vGb9tSPubTIY99bvJrjhw7y7qJvefyum2yssmLTwA8ibp9C6ab63FRLoMs5e4Ytn//v7tgmF3cv9vjUtEwWfbWeybfGMHLReu7tf4328i0ieTfBupOulqlU4PLk5rL9y3mc+WktY/q0pHWTeqX6c+NnLodfNvJ4t2jGx6dDbCft5ZfF1WOKnMeq856UUpYyxrDrmyWsnfoUd15ylDdHXl/qsC/o3Q/vmNejH94xgkVfredo+kl/lhw0dEhHqQDippvTvNm36WuS1yxg+LWNuGFM2ZdBeG/xavo3DyEmMi+aYiLD6N88RMfyLaKBr1QAcdPNaYX9vHMTP381m0Ed6jJoTPmXQVi1aS9JKdl8uC3lnOcvPrxXA98CGviqWG7vUSpnpSYnsvOzyfSKi+ClUdcREuLbKPHCV0dbVJnyRgNfFcutPUrlLI/Hw/eL36XOyb1MfaALVStXcrokVQoa+EqpMjl8YB+7Fr7B4/0uo9Ol1zpdjioDDfwKxs1DMBlpx5g97o8Me+rfREbXdLQWVXa5OTlsWDCdJiaRGaN7EB4W6nRJqow08CsYNw/BrF86h7DD21i3ZDY9h410upyA5NQNYUkJO/lhyXSeHtiK1k26+rUt5T8a+MoWGWnH2BM/n0mDYhm1aD5d+g0lIqoGe9eu5NiOr6hRKRePB7KpxCmpTPWGl9OkQzeq16hV8smDiN0/peWcPcP6eZNpVfUY7465XpcsDnBWbWLeB5gAhALTjTFjz3v9PmAc8Ev+UxONMdOtaFv5l1U9yvVL5zAgDprXqcqAuJMsfeff1K2UzZ1dG9JnxFXnTOPzeDxsT0hm8X/H8+MJDydDq1OnTXeatO5MWLheHLRL8v497Fs0hRdub0fzBs2dLkdZwOfAF5FQYBJwI5AIrBeRhcaYnecdOscYo3OuAowVPcqC3v2Ld0Rz8Fg2h1JPcHD/Uma++RS1a174wRESEkLb5rG0bR4LQPaZs3y5ZR0rZy3gSE416ne8iabtrtKdkPzo521r8GyZxztjemqvvgKxooffBdhnjEkAEJHZwEDg/MBXQWr90jn0a2aYv+kI5uwZxt9ckzfXZvD+ku9KdTNN5Urh9Lkijj5XxHE2J5fP13/Hounz8cTE0frGoVTTBc0slZWZQcq3s3lz1A36oVrBWBH4scDBQo8TgSu9HHebiHQD9gKPGWMOejkGERkBjAC4+4mX6XbLMAtKDB5uXOVxyzfLWXEgmXpRlahSKZR5u1OB8t09GR4WyoCuLRjQtQU/HzrGlAX/IDm3OnE976ROg8Z+qD74rJ/7H/5zl/4EVRH5vFqmiAwGehtjHsx/fA/QxRgzptAxFwGZxphsEfkdMMQYU+JCG7paZmDz5Oay/tNpXBaWzOODOvt8F2ZRTp7K5q1l29iYlE3dzn1p3uFaR8LKzVNiS+vHTV/TNnM1d/Zs7XQpqryKWS3Tih5+ItCw0OMGQFLhA4wxRws9nAb8y4J2lYsdS0li85x/88zAy2nbtItf24qoWplHf9MZj8fDorXrWTj1Myo16kDrnrcSXsm+bfPcPCW2NM5knyZ17TyGje7ldCnKT6wI/PVAnIg0IW8WzlDgzsIHiEh9Y0xy/sNbgF0WtKtcas93y/DsWcnbj1xn6y33ISEh3NK1Bbd0bcGWH5N5e+bzZFaN5fLedxFVM8a2OgLVxnmTeXFwRx3KqcB8DnxjTI6IjAaWkTct821jzA4ReQnYYIxZCDwqIrcAOcAx4D5f21Xuk3P2DN/NGs/NzUK448EejtbSrll9JjSrT8rxDKYs/Q9bMyvRpPtgYptd7mhdbpWUsJtWEWk0qlf0toMq8FkyD98YswRYct5zLxT6+hngGSvaUu50LCWJrXP+zUtD2tEs1j296To1q/PCnVdzOvssM7+cx9cr36NWm+tpcdWNfrumUBK3jfV7PB5+WDqNGaOK33pQBT6901b57Id1K8nZuYy3HulGlcrhTpfjVZXK4TzQpwO/NYYvNu9l7lsroW5LWt9wB1Wq2btfqtvG+rd8/gGP9m5BmK6NU+Fp4Kty8+TmsvbjifSod5rhDg/hlJaI0KtDU3p1aMq+xCNM/eQlUqhFixvuJKZ+w5JPUAw3ToktSVrqYaKO7aTLZdfZ0l5qWiYPj/2Aqc/coxuTO0ADX5XLyYx01rz3d57pfyntmgXmbffNG9Tmlftrk555irdXTOebQ7nU7dS73NM6A2XqZWGbP3mNN+/37yyqwt5bvJrjhw7qloUO0XumVZklJexk6/svMvn+K2jXrL5l501Ny+S2p6fYvmF1dGRVHhvUhXcevpJrc9ezftqf2LTkfbJPn7K1Drvt+nYpd3SMIbKaPVNXCzYon3xrjC0bkzv1/eRmGviqTHau+hTZ+AHTR/eiZlQ1S89duPfnhIJpndMe6c6Ytmf4ac6LrJ45jqOHfin5DweYUyczOLVzBbd0tW9WTsEG5S3qVP51Y3J/t+fk95Mb6ZCOKhVPbi5r5kzg5iaG24ddY/n5C/f+Ri5az739r3F0jPfyxvV49YF6pGVkMX35m3yd4uGSqwfRqFUnn8/thrH+DR+9zrg7rrCtvYJ/37lD8t7j8I4RDJnrv39nt30/uYXPSyv4ky6t4A6nTmawesbLPDvgUto2reeXNsbPXA6/bOTxbtGMj0+H2E6uGuPNzfXw/hfb+PKXcK4e9jghoYE7o2X/9nU0SV7Og307+L2tgou07S9tQETqNh7vFv3ra/78d3b795NfFbO0gg7pqGId+WU/G95+non3dvRb2Bf0xoZ3zOuBDe8YYcsYb1mEhoZw343teKrHRXw55VlOZ7mntrI4eyabxK9m8UCf9ra0VzCs8skXm/hwWzadJ6X8+uvDbdms2rTX8jYD4fvJKTqko4q0f+sasjZ+zFtjevp1/9KCsd2YyLxvx5jIsF/HeN3WK2vVuC6vDa/GY9Ofo92wp6lZ2z8fgv6yYf6bPH9bO1uWTzh3WCWLj8Y9YcuwSiB9P9lNA195tXPVp1yctomXH+zh93BYtWkvSSnZfLgt5Zzny7N8sh3q1KzO9FHdeWz6WOr3fICL49o4XVKpJCXspmXlVJo3aGZLe+depD1tW+AG2veTnXQMX53DGMPGBW/R/aJj3Hl9K6fLcTWPx8NfPlzN6SY9ibvyRlvb9rY8Q/rRVIwnhxrn/dQRGVmdP034gK8n/5EZo3tw9ZgppGZkX3DOmOqVWTd5lCX1paZlMuSpCcwdUp2YyDBSM3MYMjeDj8b9QS+e+pufl0dWFYTH42H1zHEM7xBBr/Ya9iUJCQnhpbuv5c2l6/h+STId+g0v13nKs7aOt+UZftn/A0cXjb/g+YTpY9i0aAZP9r+csLBQUjOyafXQqxecc8e0J8pVvzc6rOJOGvgKyFvpMv6tl3i6b2NLb6YKBg/3bc/S9fuY9f4rXHPnE2WewePvtXVyz56h/ul9tG9+rSXnKw0dVnEnDXzF6axMvn37L/zzjrY0qX+R0+UEpL5XNKfBRYd5ecqzXHv/C7YvyFYUYwzZJ1J5ZrC3XUf9Z+Gro21tT5WOTssMchlpR1k9/c+8fm9nDXsftWlal9fuac+a6c9x/Mghp8sB4NimJURFVKNyJXeuYqrspT18F7F7nfRjKUnsmDuWqQ93p3pEFcvPH4zq1opi+qju/H7aWGJ7OTuDJzstBU4cpkoV+7Z5VO6mge8idq6TnpKYwE+fTWDqyJ6uXcM+UFWtXIkpj/Tirx9+yJ7UHrTo2tvyNrwtz1AwSydh+hiMMZw6doiYmlHUia56znEx1St7vUAbU10/GCo6DfwglPTDNo6sepspI3vpphd+EhISwl/vvpZ3Vmxi9bz9XDFoxK/3M2SkHWP2uD8y7Kl/Exlds1xr65T0E9/GRTO4s1kW3do0uuA1q6ZeqsCjgR9kft62hrOb5/Hawz0d2+IvmNx/Y1ta7kpkwpRnuWLYH6leoxbrl84h7PA21i2ZTc9hIy0frtux6lM6VUmiW5t2lp5XBT79Hx9Edn2zmGp7FzP2vm4a9ja6qmUDptzfiR8+epntXy9hT/x8Xh0Uy574+WSmH7e0ra3LZ9PO7OKhPhr26kKW/K8XkT4iskdE9onI015erywic/JfXysija1oV5XepkUzaHNmC8/ecZUt66ioc0VHVuWN3/Xk8KoZ1PIc5ZJalRkQB+uWzLasjQ0L3+KaiIPcf2Nby86pKhafh3REJBSYBNwIJALrRWShMWZnocMeAI4bY5qLyFDgX8AdvrZd0fhjnXSPx8N3s//DkMvC6NdFe33+VtyerUfTT5KSnMjY3tH87bOf+E2nOny2cj5d+g0lMrpmudss+De+o2UYfa+43Ne3oCowK8bwuwD7jDEJACIyGxgIFA78gcBf8r/+GJgoImLcvJCPA6wayy2Y3mmM4dTxw0RHVCF+eWVL10pR3hW3Z2vBcgNdLqlKh9gqjFt1lIaVclm7eBa97nykXO2dPZPNN+/8jSdubESnSy+24i2oCsyKIZ1Y4GChx4n5z3k9xhiTA6QDXu/yEZERIrJBRDbELwy8TaHdIDMzg0b3/Isq9ePo8tDLdBw9kVYPvep1wSw3CtS9SEvas3XVpr2/rgnfdcoR5u0+y56UM3y74L1ybaOYmX6c+CnPMPa2Fhr2qlSs6OF7GxA+v+demmPynjRmKjAVdLXM8vLk5nBo+Zu07HkblSOjS/4DDihu6KO4XnJ5z2mHkpYDLmq5gVPZZ3jl40mskfq07//bUi3LcCTxJ/Z8+n+8OeI6oiOrlni8UmBNDz8RaFjocQMgqahjRCQMiAaOWdC2Os+xlCSy01Jo3XuYa8Meit5guqRecnnOaQdfdlmqWrkSL951DS/2rMH+j/7K6g9e4fDBn4o8/qct33FkxSSmj+6lYa/KxIrAXw/EiUgTEakEDAUWnnfMQuDe/K9vB77Q8XvrZaQdY8fcsVxUM5qwyu4NguJC/dxeckipw9uXDworFLcccGldUq8Wrz7QnQmDmxKz433Wv/UMaz+ayIG9O8jKOMGBPdv4+p2/0yB5JeMf7OHXXcgKBOrwmvLO58DPH5MfDSwDdgFzjTE7ROQlEbkl/7C3gItEZB/wOHDB1E3lG4/Hw/oP/sHEh9w/x76oUPell1zeDwqrFB6f93XP1qiIqvyufyemPnwtY/vWpnXKIrJWjKNN6lLeuKslj/TvaNvUWid/agL9wLGaJXfaGmOWAEvOe+6FQl+fBgZb0ZbybtOiGTzR91KiIqq6eq2UglCfOyRvqunwjhEMmbuee/tfU+5NM4o7p11j+b4uB1zU9YeYGpHc0aO1r+WVu6b/7Ulrzd9nWa+zlPd6jvJOl1aoAFKTD1Av6wc6t8jb4MLNUy+LC/XybppREXZXcmOw+WNP2rK8T3984AQ7DfwAZ4xh27zXeGekfbsZ+aK4UC9vL9lfuyvZNeunINievCqUR2YtZ8KiLYQW2jXL7vsnUtMyue9vM8hIT+OToVGANT81lTXAndoEvSLTwA9wW1fMZWSvpgGzwYU/dkLy1+5KdvW6C4KtYZQw+Iq6rAi9jobX3fbr61buNXs+bx9q7y1ezY8JPzO4TVVLf2oqS4C7YZiuInL31T1VrPSjR6iSvJHrWl+4BK7yjV2zfs6/UH17u+pk7Y7nTNaFG+H4w/kXZQvqiY0K4Z0NGXR8/bDPF6ELn7e0F+StmPWkLqQ9/AD2/ccTmHxfF6fLqJDsGk4oHGzJKVArIoyBccKKjcvP6eX7g7chloJ6Hu/WiPHx6RDbyZL3XdbrLLoJun9o4Aeo3as/Z3CHWkRFuHe+faCyczihcLD9kppBeGTeXrgStc3vgX/+h9qkj75k1botfnnfZQ1w3QTdPzTwA9Cpkxlk7VjOb0b2crqUCsnOWT+Fg63p3eNp9dCrlp6/KN4+1K57czW/7RTpl/etAe4OGvgBaMNHrzPujiucLqPCcmo4wY77Jwou0raPa3DBh1plzjBt3Qnm7Dhzzp/RYZSKQ9y8woEunnah/dvX0SR5OQ/27eB0KSoAjZ+5nEUrvuLY2UqEhVz43+viOjHaGw90V48p8jZs7eEHkLNnskn8ahYvP6pDOarszr1Im8VH4/6gUxyDjE7LDCAbF0zjuVvb6haFqlycXm9IOU8DP0Ac+vkHmoce5tKGdZwuRQUgXxamUxWHBn4A8Hg87PpsCk/eqhdqg5kvK0fqjUwKNPADwpbPZ/Jo70ttWf9cuZcvSxVbuXxzaeiyxu6kF21dLi31MNWPbeeqlt2cLqXC8/diab6c39eVI+2eeePG1T+V9vBdb/MnE3h+yJVOlxEU/L3Zhy/nD6QLrk7vPqaKpoHvYnu+W8aQDrWJrOb8xiUVnb9DypfzB9oF10D6cAo2GvgudTrrJJnbljPw6kudLiUo+DukfDl/IF1wDbQPp2Cjge9SGz6ZxPODOzpdRlDwd0j5en67L7j6IpA+nIKRTxdtRaQWMAdoDOwHhhhjjns5LhfYlv/wgDHmlvOPCWb/HD2MzMz/rX+ek30ayT7BrnUxrt6usKLw92Jpvp4/kJY60GWN3c3XWTpPA/81xowVkafzH//Jy3GnjDHtfWyrwsrMzKDpg68DYDwekpa8Rrubh7Pzraccriw4+DukgikEA+nDKRj5GvgDgR75X78LrMJ74KtSOrppKY06XIeE6Jx7u/g7pDQE/8eufYKVd76O4dc1xiQD5P9e1H3/VURkg4isEZHf+NhmhXU28zik/0LNBs2dLkUpv/D31FdVvBIDX0RWish2L78GlqGdS4wxnYE7gf8TkWbFtDci/8NhQ/zCWWVoIvAdWT2X5tcOcLoMpfxC5+c7r8QhHWPMDUW9JiKHRaS+MSZZROoDKd6OM8Yk5f+eICKrgA7Aj0UcOxWYCsG1Hn5GwiZiLr6E8CrVnC5FKb+wa59gVTRfx/AXAvcCY/N/X3D+ASJSE8gyxmSLSAxwDfCKj+1WKBHVIjjw0d+JqVWDtDWf/Pq8lTsdKeUkO/cJVkXzNfDHAnNF5EpN030AAAnVSURBVAHgADAYQEQ6A78zxjwItATeFBEPeUNIY40xO31st0Lpef11PH1dX+Ia1Ha6FKX8ws59glXRfAp8Y8xR4ILtl4wxG4AH879eDbTxpZ2K7Mgv+2kiycQ1uNrpUpTym2Camupmulqmg4wx7Fgwmbce7up0KUr5lU5NdQddWsFBu75exPBrYqlSOdzpUlQA0DXmla808B1yOiuT7D2r6N2pyBmqSp1D57ArX2ngO2TjJ2/wwpDOTpehXKaoXrzOYVdW0MB3QNKPO+hY8xT1LopyuhTlMkX14nWNeWUFDXybeTwefvj8bUYN0KWP1bmK6sXrGvPKKhr4NtuybBajbowjNFT/6tW5iurF6xrzyio6LdNGGWnHqHp4M10H9HC6FOUyxd2JqnPYlVU08G20ed5EJgzt4nQZyoWK68XrHHZlFQ18m+zfvpbrG4dRM0oXR1MX0l68soMGvg1yc3JI/GoOLz/a0+lSlEtpL17ZQa8c2uD7xe/y5IBWiIjTpSilgpgGvp8dP3KI2ln7aNO0ntOlKKWCnA7p+NnW+ROZct8VTpehlFLaw/enfRu/YmDrGkRW041MlFLO08D3k7Nnsjmy7lNuv+4yp0tRSilAA99vNi2YxjOD2umFWqWUa2jg+0Fq8kEaepJ0y0KllKto4PvBtk8n8dTteqFWKeUuGvgW2/PdMoZ2rkPVypWcLkUppc7hU+CLyGAR2SEiHhEpcjcPEekjIntEZJ+IPO1Lm26WffoU6VuXcUvXFk6XopRSF/C1h78duBWIL+oAEQkFJgF9gcuBYSJyuY/tutKm+W/y59s6OF2GUkp55VPgG2N2GWP2lHBYF2CfMSbBGHMGmA0M9KVdN0pJ/Im4Sqk0qlfL6VKUUsorO8bwY4GDhR4n5j/nlYiMEJENIrIhfuEsvxdnBWMMOxdO5olb9UKtUsq9SlxaQURWAt4WgnnOGLOgFG14m4huijrYGDMVmAowLT6hyOPcZGf8Zwy/pgGVwnWlCqWUe5WYUMaYG3xsIxFoWOhxAyDJx3O6xumsk5zZ+xW9R+rSx0opd7NjSGc9ECciTUSkEjAUWGhDu7bYOH8yf769k9NlKKVUiXydljlIRBKBrsBiEVmW//zFIrIEwBiTA4wGlgG7gLnGmB2+le0Oyfv30DYqg4trRztdilJKlcinQWdjzHxgvpfnk4B+hR4vAZb40pbbGGPYu3ga74zq5nQpSilVKnqnbTlt/2IeD13fhPCwUKdLUUqpUtHAL4eszAzM/u/o3rax06UopVSp6TzCctg0bxLjhhS5koRSSrmS9vDL6Jd92+l8UTZ1alZ3uhSllCoTDfwy8Hg87Fv2Do/07+h0KUopVWYa+GWwdcUcHrmhOaGh+temlAo8mlyldPJEGuFJG7m61SVOl6KUUuWiF21LadMnk/jPkC5Ol6GUUuWmPfxSOLh7M1fHergoOsLpUpRSqtw08Evgyc3lp/++z4g+7Z0uRSmlfKKBX4Ityz7k0d6XEhKif1VKqcCmKVaMjLRjVDuyjSsua+B0KUop5TO9aFuMzfMmMmGo7mKllKoYtIdfhAM7N9D9klBqRlVzuhSllLKEBr4Xntxcfv7yQ+6/qa3TpSillGU08L34fun7PNavpV6oVUpVKJpo5zlxPJWo47voEHex06UopZSl9KLteTbPm8TEu/RCrVKq4tEefiH7t6+lZ5NwoiOrOl2KUkpZTgM/X25ODge/msN9N+qFWqVUxeRT4IvIYBHZISIeESlyCygR2S8i20Rks4hs8KVNf9m89H2e6H85IuJ0KUop5Re+juFvB24F3izFsdcbY1J9bM8v0o8eISptF+2adXe6FKWU8hufAt8YswsI+F7xlvkTmXSPLn2slKrY7BrDN8ByEdkoIiOKO1BERojIBhHZEL9wlt8L+2nrGno1q0pUhF6oVUpVbCX28EVkJVDPy0vPGWMWlLKda4wxSSJSB1ghIruNMfHeDjTGTAWmAkyLTzClPH+55Obk8MvXc/n7oz392YxSSrlCiYFvjLnB10aMMUn5v6eIyHygC+A18O30/eJ3eXJAq4AfklJKqdLw+5COiESISPWCr4GbyLvY66i0oynUythLm6befnhRSqmKx9dpmYNEJBHoCiwWkWX5z18sIkvyD6sLfCMiW4B1wGJjzOe+tGuFrfMn8uxgvVCrlAoevs7SmQ/M9/J8EtAv/+sEoJ0v7Vjtpy2ruSmuGtUjqjhdilJK2Sbo7rTNyTlL0jcfc3fP1k6XopRStgq6wP9+0bs8eYteqFVKBZ+gCvy01MPUztpH6yZ6oVYpFXyCannkLfMmMuU+vVCrlApOrg78mOqVLDvXoQMJ3NwhlsjaDS07p1JKBRIxxq83s/qNiIzIvys3qOj7Di76voOLv993II/hF7smTwWm7zu46PsOLn5934Ec+EoppcpAA18ppYJEIAd+0I3v5dP3HVz0fQcXv77vgL1oq5RSqmwCuYevlFKqDDTwlVIqSAR04IvIOBHZLSJbRWS+iNRwuiY7iMhgEdkhIh4R6ex0Pf4mIn1EZI+I7BORp52uxw4i8raIpIiI43tH2EVEGorIlyKyK//7+/dO12QHEakiIutEZEv++/6rv9oK6MAHVgCtjTFtgb3AMw7XY5ftwK24YNcwfxORUGAS0Be4HBgmIpc7W5UtZgB9nC7CZjnAE8aYlsBVwKgg+bfOBnoaY9oB7YE+InKVPxoK6MA3xiw3xuTkP1wDNHCyHrsYY3YZY/Y4XYdNugD7jDEJxpgzwGxgoMM1+V3+ns/HnK7DTsaYZGPMpvyvM4BdQKyzVfmfyZOZ/zA8/5dfZtMEdOCf57fAUqeLUJaLBQ4WepxIEIRAsBORxkAHYK2zldhDREJFZDOQAqwwxvjlfbt68TQAEVkJeFvP+DljzIL8Y54j78fBmXbW5k+led9BwtvGBTqXuAITkUjgE+APxpgTTtdjB2NMLtA+/zrkfBFpbYyx/PqN6wPfGHNDca+LyL1Af6CXqUA3FZT0voNIIlB4idMGQJJDtSg/E5Fw8sJ+pjFmntP12M0YkyYiq8i7fmN54Af0kI6I9AH+BNxijMlyuh7lF+uBOBFpIiKVgKHAQodrUn4gedvQvQXsMsaMd7oeu4hI7YIZhiJSFbgB2O2PtgI68IGJQHVghYhsFpEpThdkBxEZJCKJQFdgsYgsc7omf8m/KD8aWEbeRby5xpgdzlblfyIyC/gOaCEiiSLygNM12eAa4B6gZ/7/580i0s/pomxQH/hSRLaS18FZYYxZ5I+GdGkFpZQKEoHew1dKKVVKGvhKKRUkNPCVUipIaOArpVSQ0MBXSqkgoYGvlFJBQgNfKaWCxP8DLoPQm5AXQFYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
