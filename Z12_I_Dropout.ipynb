{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 41)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15060, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               4200      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30162 samples, validate on 15060 samples\n",
      "Epoch 1/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.5906 - accuracy: 0.7224 - val_loss: 0.5417 - val_accuracy: 0.7543\n",
      "Epoch 2/100\n",
      "30162/30162 [==============================] - 2s 63us/step - loss: 0.5418 - accuracy: 0.7502 - val_loss: 0.4799 - val_accuracy: 0.7543\n",
      "Epoch 3/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.4769 - accuracy: 0.7723 - val_loss: 0.4143 - val_accuracy: 0.8107\n",
      "Epoch 4/100\n",
      "30162/30162 [==============================] - 2s 65us/step - loss: 0.4353 - accuracy: 0.7921 - val_loss: 0.3858 - val_accuracy: 0.8343\n",
      "Epoch 5/100\n",
      "30162/30162 [==============================] - 2s 61us/step - loss: 0.4154 - accuracy: 0.8048 - val_loss: 0.3727 - val_accuracy: 0.8374\n",
      "Epoch 6/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.4037 - accuracy: 0.8103 - val_loss: 0.3653 - val_accuracy: 0.8383\n",
      "Epoch 7/100\n",
      "30162/30162 [==============================] - 2s 62us/step - loss: 0.3954 - accuracy: 0.8117 - val_loss: 0.3606 - val_accuracy: 0.8364\n",
      "Epoch 8/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.3898 - accuracy: 0.8152 - val_loss: 0.3574 - val_accuracy: 0.8373\n",
      "Epoch 9/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3885 - accuracy: 0.8184 - val_loss: 0.3552 - val_accuracy: 0.8367\n",
      "Epoch 10/100\n",
      "30162/30162 [==============================] - 2s 60us/step - loss: 0.3826 - accuracy: 0.8191 - val_loss: 0.3538 - val_accuracy: 0.8366\n",
      "Epoch 11/100\n",
      "30162/30162 [==============================] - 2s 77us/step - loss: 0.3828 - accuracy: 0.8212 - val_loss: 0.3527 - val_accuracy: 0.8369\n",
      "Epoch 12/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.3800 - accuracy: 0.8257 - val_loss: 0.3518 - val_accuracy: 0.8378\n",
      "Epoch 13/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3781 - accuracy: 0.8227 - val_loss: 0.3508 - val_accuracy: 0.8377\n",
      "Epoch 14/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3778 - accuracy: 0.8229 - val_loss: 0.3500 - val_accuracy: 0.8383\n",
      "Epoch 15/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3757 - accuracy: 0.8267 - val_loss: 0.3491 - val_accuracy: 0.8387\n",
      "Epoch 16/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.3766 - accuracy: 0.8244 - val_loss: 0.3483 - val_accuracy: 0.8392\n",
      "Epoch 17/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3754 - accuracy: 0.8245 - val_loss: 0.3477 - val_accuracy: 0.8401\n",
      "Epoch 18/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3744 - accuracy: 0.8245 - val_loss: 0.3470 - val_accuracy: 0.8408\n",
      "Epoch 19/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3719 - accuracy: 0.8292 - val_loss: 0.3462 - val_accuracy: 0.8412\n",
      "Epoch 20/100\n",
      "30162/30162 [==============================] - 2s 63us/step - loss: 0.3724 - accuracy: 0.8296 - val_loss: 0.3459 - val_accuracy: 0.8414\n",
      "Epoch 21/100\n",
      "30162/30162 [==============================] - 2s 65us/step - loss: 0.3740 - accuracy: 0.8238 - val_loss: 0.3456 - val_accuracy: 0.8416\n",
      "Epoch 22/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3693 - accuracy: 0.8296 - val_loss: 0.3452 - val_accuracy: 0.8421\n",
      "Epoch 23/100\n",
      "30162/30162 [==============================] - 2s 65us/step - loss: 0.3717 - accuracy: 0.8269 - val_loss: 0.3450 - val_accuracy: 0.8420\n",
      "Epoch 24/100\n",
      "30162/30162 [==============================] - 2s 63us/step - loss: 0.3733 - accuracy: 0.8266 - val_loss: 0.3447 - val_accuracy: 0.8424\n",
      "Epoch 25/100\n",
      "30162/30162 [==============================] - 2s 63us/step - loss: 0.3725 - accuracy: 0.8266 - val_loss: 0.3444 - val_accuracy: 0.8425\n",
      "Epoch 26/100\n",
      "30162/30162 [==============================] - 2s 65us/step - loss: 0.3710 - accuracy: 0.8273 - val_loss: 0.3442 - val_accuracy: 0.8426\n",
      "Epoch 27/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3693 - accuracy: 0.8294 - val_loss: 0.3438 - val_accuracy: 0.8425\n",
      "Epoch 28/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3693 - accuracy: 0.8288 - val_loss: 0.3436 - val_accuracy: 0.8426\n",
      "Epoch 29/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3676 - accuracy: 0.8332 - val_loss: 0.3432 - val_accuracy: 0.8434\n",
      "Epoch 30/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3688 - accuracy: 0.8304 - val_loss: 0.3431 - val_accuracy: 0.8432\n",
      "Epoch 31/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.3657 - accuracy: 0.8309 - val_loss: 0.3429 - val_accuracy: 0.8433\n",
      "Epoch 32/100\n",
      "30162/30162 [==============================] - 2s 63us/step - loss: 0.3697 - accuracy: 0.8298 - val_loss: 0.3428 - val_accuracy: 0.8433\n",
      "Epoch 33/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.3680 - accuracy: 0.8294 - val_loss: 0.3427 - val_accuracy: 0.8435\n",
      "Epoch 34/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.3698 - accuracy: 0.8279 - val_loss: 0.3426 - val_accuracy: 0.8435\n",
      "Epoch 35/100\n",
      "30162/30162 [==============================] - 2s 63us/step - loss: 0.3677 - accuracy: 0.8292 - val_loss: 0.3424 - val_accuracy: 0.8436\n",
      "Epoch 36/100\n",
      "30162/30162 [==============================] - 2s 62us/step - loss: 0.3676 - accuracy: 0.8305 - val_loss: 0.3423 - val_accuracy: 0.8434\n",
      "Epoch 37/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3673 - accuracy: 0.8296 - val_loss: 0.3421 - val_accuracy: 0.8440\n",
      "Epoch 38/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.3711 - accuracy: 0.8276 - val_loss: 0.3420 - val_accuracy: 0.8444\n",
      "Epoch 39/100\n",
      "30162/30162 [==============================] - 2s 61us/step - loss: 0.3680 - accuracy: 0.8292 - val_loss: 0.3419 - val_accuracy: 0.8444\n",
      "Epoch 40/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3663 - accuracy: 0.8310 - val_loss: 0.3419 - val_accuracy: 0.8444\n",
      "Epoch 41/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.3677 - accuracy: 0.8316 - val_loss: 0.3418 - val_accuracy: 0.8443\n",
      "Epoch 42/100\n",
      "30162/30162 [==============================] - 2s 65us/step - loss: 0.3676 - accuracy: 0.8310 - val_loss: 0.3417 - val_accuracy: 0.8442\n",
      "Epoch 43/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3676 - accuracy: 0.8285 - val_loss: 0.3416 - val_accuracy: 0.8446\n",
      "Epoch 44/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3662 - accuracy: 0.8295 - val_loss: 0.3416 - val_accuracy: 0.8445\n",
      "Epoch 45/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.3688 - accuracy: 0.8296 - val_loss: 0.3415 - val_accuracy: 0.8444\n",
      "Epoch 46/100\n",
      "30162/30162 [==============================] - 2s 78us/step - loss: 0.3660 - accuracy: 0.8303 - val_loss: 0.3415 - val_accuracy: 0.8445\n",
      "Epoch 47/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3691 - accuracy: 0.8294 - val_loss: 0.3414 - val_accuracy: 0.8445\n",
      "Epoch 48/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3664 - accuracy: 0.8299 - val_loss: 0.3413 - val_accuracy: 0.8444\n",
      "Epoch 49/100\n",
      "30162/30162 [==============================] - 2s 79us/step - loss: 0.3664 - accuracy: 0.8293 - val_loss: 0.3413 - val_accuracy: 0.8445\n",
      "Epoch 50/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3643 - accuracy: 0.8308 - val_loss: 0.3413 - val_accuracy: 0.8446\n",
      "Epoch 51/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3640 - accuracy: 0.8316 - val_loss: 0.3412 - val_accuracy: 0.8446\n",
      "Epoch 52/100\n",
      "30162/30162 [==============================] - 2s 79us/step - loss: 0.3681 - accuracy: 0.8308 - val_loss: 0.3412 - val_accuracy: 0.8446\n",
      "Epoch 53/100\n",
      "30162/30162 [==============================] - 2s 75us/step - loss: 0.3635 - accuracy: 0.8308 - val_loss: 0.3411 - val_accuracy: 0.8445\n",
      "Epoch 54/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3650 - accuracy: 0.8312 - val_loss: 0.3411 - val_accuracy: 0.8446\n",
      "Epoch 55/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3671 - accuracy: 0.8322 - val_loss: 0.3411 - val_accuracy: 0.8446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3668 - accuracy: 0.8316 - val_loss: 0.3411 - val_accuracy: 0.8448\n",
      "Epoch 57/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.3678 - accuracy: 0.8311 - val_loss: 0.3410 - val_accuracy: 0.8448\n",
      "Epoch 58/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3649 - accuracy: 0.8301 - val_loss: 0.3410 - val_accuracy: 0.8446\n",
      "Epoch 59/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3674 - accuracy: 0.8303 - val_loss: 0.3410 - val_accuracy: 0.8448\n",
      "Epoch 60/100\n",
      "30162/30162 [==============================] - 2s 81us/step - loss: 0.3675 - accuracy: 0.8315 - val_loss: 0.3410 - val_accuracy: 0.8446\n",
      "Epoch 61/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3677 - accuracy: 0.8300 - val_loss: 0.3409 - val_accuracy: 0.8446\n",
      "Epoch 62/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3681 - accuracy: 0.8311 - val_loss: 0.3409 - val_accuracy: 0.8447\n",
      "Epoch 63/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3669 - accuracy: 0.8291 - val_loss: 0.3409 - val_accuracy: 0.8446\n",
      "Epoch 64/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3649 - accuracy: 0.8311 - val_loss: 0.3409 - val_accuracy: 0.8446\n",
      "Epoch 65/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3686 - accuracy: 0.8283 - val_loss: 0.3409 - val_accuracy: 0.8448\n",
      "Epoch 66/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3649 - accuracy: 0.8304 - val_loss: 0.3409 - val_accuracy: 0.8448\n",
      "Epoch 67/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3657 - accuracy: 0.8318 - val_loss: 0.3409 - val_accuracy: 0.8449\n",
      "Epoch 68/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3662 - accuracy: 0.8302 - val_loss: 0.3409 - val_accuracy: 0.8450\n",
      "Epoch 69/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3655 - accuracy: 0.8310 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
      "Epoch 70/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.3645 - accuracy: 0.8310 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
      "Epoch 71/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3655 - accuracy: 0.8332 - val_loss: 0.3408 - val_accuracy: 0.8448\n",
      "Epoch 72/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.3663 - accuracy: 0.8307 - val_loss: 0.3408 - val_accuracy: 0.8449\n",
      "Epoch 73/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3662 - accuracy: 0.8296 - val_loss: 0.3408 - val_accuracy: 0.8449\n",
      "Epoch 74/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3639 - accuracy: 0.8333 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
      "Epoch 75/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3660 - accuracy: 0.8307 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
      "Epoch 76/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3659 - accuracy: 0.8309 - val_loss: 0.3408 - val_accuracy: 0.8449\n",
      "Epoch 77/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.3662 - accuracy: 0.8326 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
      "Epoch 78/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3663 - accuracy: 0.8309 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
      "Epoch 79/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3651 - accuracy: 0.8315 - val_loss: 0.3408 - val_accuracy: 0.8449\n",
      "Epoch 80/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.3659 - accuracy: 0.8312 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
      "Epoch 81/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3637 - accuracy: 0.8302 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
      "Epoch 82/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3654 - accuracy: 0.8316 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 83/100\n",
      "30162/30162 [==============================] - 2s 65us/step - loss: 0.3688 - accuracy: 0.8293 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 84/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3657 - accuracy: 0.8321 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 85/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3643 - accuracy: 0.8310 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 86/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3659 - accuracy: 0.8291 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 87/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3662 - accuracy: 0.8308 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 88/100\n",
      "30162/30162 [==============================] - 2s 77us/step - loss: 0.3649 - accuracy: 0.8307 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 89/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3660 - accuracy: 0.8315 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 90/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3639 - accuracy: 0.8307 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 91/100\n",
      "30162/30162 [==============================] - 2s 65us/step - loss: 0.3665 - accuracy: 0.8280 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 92/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3655 - accuracy: 0.8307 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 93/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.3664 - accuracy: 0.8310 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 94/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3658 - accuracy: 0.8309 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 95/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3649 - accuracy: 0.8301 - val_loss: 0.3407 - val_accuracy: 0.8451\n",
      "Epoch 96/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3642 - accuracy: 0.8317 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 97/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3669 - accuracy: 0.8279 - val_loss: 0.3407 - val_accuracy: 0.8451\n",
      "Epoch 98/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3638 - accuracy: 0.8316 - val_loss: 0.3407 - val_accuracy: 0.8451\n",
      "Epoch 99/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.3647 - accuracy: 0.8335 - val_loss: 0.3407 - val_accuracy: 0.8451\n",
      "Epoch 100/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3633 - accuracy: 0.8323 - val_loss: 0.3407 - val_accuracy: 0.8451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2c4b682198>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate, history_Adam, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Do poniszego modelu dodaj\n",
    "```python\n",
    "model.add(Dropout(0.8))\n",
    "```\n",
    "w kadej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki:\n",
    "\n",
    "* porwnaj krzywe uczenia\n",
    "* narysuj granice decyzyjne (dane s w 2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=5)\n",
    "\n",
    "n_train=53\n",
    "X_train, X_test = X[:n_train, :], X[n_train:, :]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "plt.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.8822 - accuracy: 0.4528 - val_loss: 0.7570 - val_accuracy: 0.4468\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.7506 - accuracy: 0.5472 - val_loss: 0.8548 - val_accuracy: 0.4468\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.7308 - accuracy: 0.5472 - val_loss: 0.6965 - val_accuracy: 0.4468\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.6707 - accuracy: 0.6226 - val_loss: 0.6336 - val_accuracy: 0.7021\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.6478 - accuracy: 0.6226 - val_loss: 0.6204 - val_accuracy: 0.6170\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.6134 - accuracy: 0.7170 - val_loss: 0.5966 - val_accuracy: 0.7447\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.5636 - accuracy: 0.8679 - val_loss: 0.5953 - val_accuracy: 0.7447\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.5647 - accuracy: 0.7736 - val_loss: 0.5900 - val_accuracy: 0.7447\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.5257 - accuracy: 0.7925 - val_loss: 0.5387 - val_accuracy: 0.7872\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.4719 - accuracy: 0.8302 - val_loss: 0.5066 - val_accuracy: 0.7447\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.4364 - accuracy: 0.8491 - val_loss: 0.5012 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4108 - accuracy: 0.8491 - val_loss: 0.5045 - val_accuracy: 0.7660\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3885 - accuracy: 0.8302 - val_loss: 0.5027 - val_accuracy: 0.7660\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.3625 - accuracy: 0.8491 - val_loss: 0.4916 - val_accuracy: 0.7447\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.3450 - accuracy: 0.8491 - val_loss: 0.4848 - val_accuracy: 0.7447\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.3331 - accuracy: 0.8491 - val_loss: 0.4882 - val_accuracy: 0.7447\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.3281 - accuracy: 0.8679 - val_loss: 0.4966 - val_accuracy: 0.7447\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.3200 - accuracy: 0.8491 - val_loss: 0.5120 - val_accuracy: 0.7447\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3191 - accuracy: 0.8491 - val_loss: 0.5316 - val_accuracy: 0.7660\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3045 - accuracy: 0.8679 - val_loss: 0.5340 - val_accuracy: 0.7660\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2963 - accuracy: 0.8679 - val_loss: 0.5232 - val_accuracy: 0.7872\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.2892 - accuracy: 0.8868 - val_loss: 0.5090 - val_accuracy: 0.7872\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2854 - accuracy: 0.8868 - val_loss: 0.5036 - val_accuracy: 0.7872\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2750 - accuracy: 0.8868 - val_loss: 0.4842 - val_accuracy: 0.8085\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2679 - accuracy: 0.8868 - val_loss: 0.4763 - val_accuracy: 0.8085\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2616 - accuracy: 0.8868 - val_loss: 0.4791 - val_accuracy: 0.8085\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.2567 - accuracy: 0.9057 - val_loss: 0.4810 - val_accuracy: 0.8085\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.2541 - accuracy: 0.9057 - val_loss: 0.4761 - val_accuracy: 0.8085\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.2507 - accuracy: 0.9057 - val_loss: 0.4629 - val_accuracy: 0.8085\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.2516 - accuracy: 0.8868 - val_loss: 0.4512 - val_accuracy: 0.8085\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2431 - accuracy: 0.9057 - val_loss: 0.4591 - val_accuracy: 0.8085\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9057 - val_loss: 0.4674 - val_accuracy: 0.8085\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 982us/step - loss: 0.2397 - accuracy: 0.9057 - val_loss: 0.4644 - val_accuracy: 0.8085\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.2348 - accuracy: 0.8868 - val_loss: 0.4711 - val_accuracy: 0.8085\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2330 - accuracy: 0.8868 - val_loss: 0.4793 - val_accuracy: 0.8298\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2315 - accuracy: 0.8868 - val_loss: 0.4782 - val_accuracy: 0.8298\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2291 - accuracy: 0.8868 - val_loss: 0.4818 - val_accuracy: 0.8298\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2260 - accuracy: 0.8868 - val_loss: 0.4753 - val_accuracy: 0.8298\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2237 - accuracy: 0.8868 - val_loss: 0.4746 - val_accuracy: 0.8298\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2217 - accuracy: 0.9057 - val_loss: 0.4729 - val_accuracy: 0.8298\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.2216 - accuracy: 0.9057 - val_loss: 0.4676 - val_accuracy: 0.8298\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2180 - accuracy: 0.9057 - val_loss: 0.4762 - val_accuracy: 0.8298\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2142 - accuracy: 0.8868 - val_loss: 0.4917 - val_accuracy: 0.8085\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2139 - accuracy: 0.8868 - val_loss: 0.5004 - val_accuracy: 0.8085\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.2156 - accuracy: 0.9245 - val_loss: 0.5034 - val_accuracy: 0.8085\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 0.2128 - accuracy: 0.9057 - val_loss: 0.4800 - val_accuracy: 0.8298\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2072 - accuracy: 0.8868 - val_loss: 0.4647 - val_accuracy: 0.8298\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2082 - accuracy: 0.9057 - val_loss: 0.4450 - val_accuracy: 0.8298\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2068 - accuracy: 0.9057 - val_loss: 0.4462 - val_accuracy: 0.8298\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2033 - accuracy: 0.9057 - val_loss: 0.4494 - val_accuracy: 0.8298\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2008 - accuracy: 0.9057 - val_loss: 0.4618 - val_accuracy: 0.8298\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1964 - accuracy: 0.9245 - val_loss: 0.4859 - val_accuracy: 0.8085\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1995 - accuracy: 0.9245 - val_loss: 0.5057 - val_accuracy: 0.8085\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2002 - accuracy: 0.9245 - val_loss: 0.4984 - val_accuracy: 0.8085\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1958 - accuracy: 0.9245 - val_loss: 0.4901 - val_accuracy: 0.8298\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1921 - accuracy: 0.9245 - val_loss: 0.4715 - val_accuracy: 0.8298\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1923 - accuracy: 0.9057 - val_loss: 0.4448 - val_accuracy: 0.8298\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1973 - accuracy: 0.9057 - val_loss: 0.4379 - val_accuracy: 0.8298\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1968 - accuracy: 0.9057 - val_loss: 0.4567 - val_accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1888 - accuracy: 0.9434 - val_loss: 0.4689 - val_accuracy: 0.8298\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1832 - accuracy: 0.9434 - val_loss: 0.4689 - val_accuracy: 0.8298\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1809 - accuracy: 0.9434 - val_loss: 0.4582 - val_accuracy: 0.8298\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1797 - accuracy: 0.9245 - val_loss: 0.4430 - val_accuracy: 0.8298\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1775 - accuracy: 0.9245 - val_loss: 0.4368 - val_accuracy: 0.8298\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1761 - accuracy: 0.9245 - val_loss: 0.4264 - val_accuracy: 0.8298\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1740 - accuracy: 0.9245 - val_loss: 0.4098 - val_accuracy: 0.8298\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1746 - accuracy: 0.9245 - val_loss: 0.4056 - val_accuracy: 0.8298\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1737 - accuracy: 0.9245 - val_loss: 0.3962 - val_accuracy: 0.8511\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1719 - accuracy: 0.9245 - val_loss: 0.4030 - val_accuracy: 0.8298\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1678 - accuracy: 0.9245 - val_loss: 0.4318 - val_accuracy: 0.8298\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1675 - accuracy: 0.9811 - val_loss: 0.4442 - val_accuracy: 0.8298\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.1656 - accuracy: 0.9811 - val_loss: 0.4329 - val_accuracy: 0.8298\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1629 - accuracy: 0.9623 - val_loss: 0.4105 - val_accuracy: 0.8298\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1577 - accuracy: 0.9245 - val_loss: 0.4007 - val_accuracy: 0.8511\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1580 - accuracy: 0.9245 - val_loss: 0.3992 - val_accuracy: 0.8511\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1587 - accuracy: 0.9434 - val_loss: 0.4134 - val_accuracy: 0.8298\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1509 - accuracy: 0.9623 - val_loss: 0.4143 - val_accuracy: 0.8298\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1508 - accuracy: 0.9623 - val_loss: 0.4127 - val_accuracy: 0.8298\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1499 - accuracy: 0.9623 - val_loss: 0.4004 - val_accuracy: 0.8511\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1447 - accuracy: 0.9623 - val_loss: 0.4029 - val_accuracy: 0.8511\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1421 - accuracy: 0.9623 - val_loss: 0.4135 - val_accuracy: 0.8511\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1421 - accuracy: 0.9811 - val_loss: 0.4137 - val_accuracy: 0.8511\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1384 - accuracy: 0.9811 - val_loss: 0.3930 - val_accuracy: 0.8723\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1346 - accuracy: 0.9623 - val_loss: 0.3770 - val_accuracy: 0.8511\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1363 - accuracy: 0.9623 - val_loss: 0.3614 - val_accuracy: 0.8511\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1336 - accuracy: 0.9623 - val_loss: 0.3691 - val_accuracy: 0.8723\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1296 - accuracy: 0.9623 - val_loss: 0.3644 - val_accuracy: 0.8723\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1249 - accuracy: 0.9623 - val_loss: 0.3713 - val_accuracy: 0.8723\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1242 - accuracy: 0.9811 - val_loss: 0.3832 - val_accuracy: 0.8723\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1240 - accuracy: 0.9811 - val_loss: 0.3679 - val_accuracy: 0.8723\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1199 - accuracy: 0.9811 - val_loss: 0.3520 - val_accuracy: 0.8723\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1161 - accuracy: 0.9811 - val_loss: 0.3310 - val_accuracy: 0.8723\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1126 - accuracy: 0.9811 - val_loss: 0.3184 - val_accuracy: 0.8723\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1114 - accuracy: 0.9811 - val_loss: 0.3070 - val_accuracy: 0.8511\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1092 - accuracy: 0.9811 - val_loss: 0.3000 - val_accuracy: 0.8511\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1058 - accuracy: 0.9811 - val_loss: 0.3045 - val_accuracy: 0.8723\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1030 - accuracy: 0.9811 - val_loss: 0.3041 - val_accuracy: 0.8936\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1004 - accuracy: 0.9811 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0993 - accuracy: 0.9811 - val_loss: 0.3078 - val_accuracy: 0.8936\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0958 - accuracy: 0.9811 - val_loss: 0.2896 - val_accuracy: 0.8723\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0937 - accuracy: 0.9811 - val_loss: 0.2669 - val_accuracy: 0.8723\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0914 - accuracy: 0.9811 - val_loss: 0.2562 - val_accuracy: 0.8723\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0895 - accuracy: 0.9811 - val_loss: 0.2557 - val_accuracy: 0.8723\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0854 - accuracy: 0.9811 - val_loss: 0.2687 - val_accuracy: 0.8936\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0860 - accuracy: 0.9811 - val_loss: 0.2837 - val_accuracy: 0.8936\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0831 - accuracy: 0.9811 - val_loss: 0.2686 - val_accuracy: 0.8936\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 585us/step - loss: 0.0789 - accuracy: 0.9811 - val_loss: 0.2549 - val_accuracy: 0.8936\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0765 - accuracy: 0.9811 - val_loss: 0.2341 - val_accuracy: 0.8936\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0747 - accuracy: 0.9811 - val_loss: 0.2244 - val_accuracy: 0.8936\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0740 - accuracy: 0.9811 - val_loss: 0.2206 - val_accuracy: 0.8936\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 643us/step - loss: 0.0712 - accuracy: 0.9811 - val_loss: 0.2285 - val_accuracy: 0.8936\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0698 - accuracy: 0.9811 - val_loss: 0.2360 - val_accuracy: 0.8936\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0657 - accuracy: 0.9811 - val_loss: 0.2513 - val_accuracy: 0.8936\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0663 - accuracy: 0.9811 - val_loss: 0.2562 - val_accuracy: 0.8936\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0671 - accuracy: 0.9811 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0616 - accuracy: 0.9811 - val_loss: 0.2217 - val_accuracy: 0.9149\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0599 - accuracy: 0.9811 - val_loss: 0.2020 - val_accuracy: 0.9149\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9149\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.8936\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.8936\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 718us/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9149\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9149\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9149\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9149\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 0.2004 - val_accuracy: 0.9149\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0489 - accuracy: 0.9811 - val_loss: 0.1778 - val_accuracy: 0.9149\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9149\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9149\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9149\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9149\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0469 - accuracy: 0.9811 - val_loss: 0.2095 - val_accuracy: 0.9149\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9149\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9149\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 0.8936\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9149\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9149\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9149\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9149\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9149\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9362\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.8936\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.8936\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.8936\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9149\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9149\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9149\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9149\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9149\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9149\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9149\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.8936\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9362\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9362\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9362\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9362\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9149\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.8936\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9149\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9149\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.8936\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.8936\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.8936\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.8936\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.8936\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.8936\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.8936\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.8936\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.8936\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9149\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9149\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9149\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.8936\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.8936\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.8936\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.8936\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.8936\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.8936\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.8936\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.8936\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.8936\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9149\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.8936\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9149\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.8936\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.8936\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.8936\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.8936\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9149\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.8936\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9149\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9149\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9149\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9149\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9149\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9149\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 567us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9149\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9149\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.8936\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9149\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9149\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9149\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9149\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9149\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9149\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9149\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9149\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9362\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9149\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9149\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9149\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9149\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9149\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9149\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9149\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9149\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9149\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9149\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9149\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 566us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9149\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9149\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9149\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9149\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9149\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9149\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9149\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9149\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9149\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9149\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9149\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9149\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9149\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9149\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9149\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9149\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9149\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9149\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9149\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9149\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 963us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9149\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9149\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9149\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9149\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9149\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9149\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9149\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9149\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9149\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9149\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9149\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9149\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9149\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9149\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9149\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9149\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9149\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9149\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9149\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9149\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9149\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9149\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9149\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9149\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9149\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9149\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9149\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9149\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9149\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9149\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9149\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9149\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9149\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9149\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 548us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9149\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9149\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9149\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9149\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9149\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9149\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9149\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9149\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9149\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9149\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9149\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9149\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9149\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9149\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9149\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9149\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9149\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9149\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9149\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9149\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9149\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9149\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9149\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9149\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9149\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9149\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9149\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9149\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9149\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9149\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9149\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9149\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9149\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9149\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9149\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9149\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9149\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9149\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9149\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9149\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9149\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9149\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9149\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9149\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9149\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9149\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9149\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9149\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9149\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9149\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9149\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9149\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9149\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 8.7672e-04 - accuracy: 1.00 - 0s 529us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9149\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 567us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9149\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9149\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9149\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9149\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9149\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9149\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9149\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9149\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9149\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9149\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9149\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9149\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9149\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9149\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9149\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9149\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9149\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9149\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9149\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9149\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9149\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9149\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9149\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9149\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9149\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9149\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9149\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9149\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9149\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9149\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9149\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9149\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9149\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 566us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9149\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9149\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9149\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9149\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9149\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9149\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9149\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9149\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9149\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9149\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9149\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9149\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9149\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9149\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9149\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9149\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9149\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9149\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9149\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9149\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9149\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9149\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9149\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9149\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9149\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9149\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9149\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9149\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9149\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9149\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9149\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9149\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9149\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9149\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9149\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 601us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9149\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9149\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9149\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9149\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9149\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9149\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9149\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9149\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9149\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9149\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9149\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9149\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9149\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9149\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9149\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9149\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9149\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9149\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9149\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9149\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9149\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9149\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9149\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9149\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9149\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9149\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9149\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9149\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9149\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9149\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9149\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9149\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9149\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9149\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9149\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9149\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9149\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9149\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9149\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9149\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9149\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9149\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9149\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9149\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9149\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9149\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9149\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9149\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9149\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9149\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9149\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9149\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9149\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9149\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9149\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9149\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9149\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9149\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9149\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9149\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9149\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 626us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9149\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9149\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9149\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9149\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9149\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9149\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9149\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9149\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9149\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9149\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9149\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9149\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9149\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9149\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9149\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9149\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9149\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9149\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9149\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9149\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9149\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9149\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9149\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9149\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9149\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9149\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9149\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
      "Epoch 499/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 623us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9149\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9149\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9149\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 9.9868e-04 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9149\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 9.8344e-04 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9149\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 9.9346e-04 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9149\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9149\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 9.9977e-04 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9149\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 9.5934e-04 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9149\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 9.6214e-04 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9149\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9149\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 9.9607e-04 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9149\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 9.6266e-04 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9149\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 9.4237e-04 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9149\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 9.3836e-04 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9149\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 9.4347e-04 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9149\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 9.5878e-04 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9149\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 9.3659e-04 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 9.6225e-04 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9149\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 9.1519e-04 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9149\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 9.3583e-04 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9149\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 9.0551e-04 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9149\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 9.0170e-04 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9149\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 567us/step - loss: 8.9614e-04 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9149\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 9.1352e-04 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9149\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 8.8718e-04 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9149\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.8438e-04 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9149\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.9751e-04 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9149\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.7561e-04 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9149\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.8643e-04 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9149\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.7882e-04 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9149\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 8.6667e-04 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9149\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 9.0007e-04 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9149\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.6909e-04 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9149\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 9.0855e-04 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.4880e-04 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9149\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 716us/step - loss: 8.8385e-04 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9149\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 8.4965e-04 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9149\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.7249e-04 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9149\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 8.5316e-04 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9149\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 8.2715e-04 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.2071e-04 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9149\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.2721e-04 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9149\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 8.2111e-04 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9149\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 8.1818e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.2389e-04 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9149\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 8.6662e-04 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.2444e-04 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9149\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 8.4672e-04 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9149\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 7.9109e-04 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9149\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 7.8945e-04 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 7.9023e-04 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9149\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 7.9875e-04 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9149\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 7.7381e-04 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9149\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 7.6960e-04 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 7.7759e-04 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9149\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 7.8914e-04 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9149\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 7.8336e-04 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9149\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 7.7146e-04 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9149\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 7.6927e-04 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9149\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 7.5889e-04 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9149\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 7.4502e-04 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9149\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 7.4549e-04 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9149\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 7.3504e-04 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9149\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 831us/step - loss: 7.3546e-04 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9149\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 7.4767e-04 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9149\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 7.5909e-04 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9149\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 7.5541e-04 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9149\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 7.4169e-04 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9149\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 7.1125e-04 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9149\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 6.9837e-04 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9149\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 7.4184e-04 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9149\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 7.8960e-04 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9149\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 7.3969e-04 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9149\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 7.5924e-04 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9149\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 6.9909e-04 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9149\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 7.2786e-04 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9149\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 547us/step - loss: 7.0332e-04 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9149\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.9492e-04 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9149\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 7.2309e-04 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9149\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 6.9306e-04 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9149\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 547us/step - loss: 6.8192e-04 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9149\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.8322e-04 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9149\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 6.7986e-04 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9149\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.9046e-04 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9149\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.7858e-04 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.6328e-04 - accuracy: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.9149\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 6.5987e-04 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9149\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.6601e-04 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9149\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 6.5625e-04 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9149\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.5744e-04 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9149\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 6.6638e-04 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9149\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 6.5094e-04 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9149\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 6.4747e-04 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9149\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.5090e-04 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9149\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 6.3886e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 6.3441e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9149\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 6.3745e-04 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9149\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 6.4938e-04 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9149\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 6.4816e-04 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9149\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 6.4407e-04 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9149\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.5186e-04 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9149\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 6.2057e-04 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9149\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 6.2441e-04 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9149\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.1306e-04 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9149\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.1272e-04 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9149\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.4497e-04 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9149\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 6.4080e-04 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9149\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 6.1740e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9149\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 6.0090e-04 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9149\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 5.8830e-04 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9149\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.0863e-04 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9149\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.3906e-04 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9149\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 6.1690e-04 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9149\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 5.8380e-04 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9149\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 5.8513e-04 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9149\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 6.3573e-04 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9149\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 6.1947e-04 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 6.0828e-04 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9149\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 5.8392e-04 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9149\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 5.7222e-04 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9149\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 5.7265e-04 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9149\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.0017e-04 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.9149\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 5.8112e-04 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.9149\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 5.6828e-04 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9149\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 5.6133e-04 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9149\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 5.8614e-04 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9149\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 5.7612e-04 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9149\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 5.5767e-04 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9149\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7626e-04 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9149\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 5.5557e-04 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9149\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 5.4787e-04 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9149\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 821us/step - loss: 5.5308e-04 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9149\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 5.6594e-04 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9149\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 5.5247e-04 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9149\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 5.3458e-04 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9149\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 5.6842e-04 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9149\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 595us/step - loss: 5.4161e-04 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9149\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 578us/step - loss: 5.4301e-04 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9149\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 5.3785e-04 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9149\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 5.3009e-04 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9149\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 5.2462e-04 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9149\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 5.2181e-04 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9149\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 5.2207e-04 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9149\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 5.2102e-04 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9149\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 5.2642e-04 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9149\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 5.1265e-04 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9149\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 5.1087e-04 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9149\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 5.0715e-04 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9149\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 5.0934e-04 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 5.4325e-04 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9149\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 5.2577e-04 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9149\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.1352e-04 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9149\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 5.1968e-04 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9149\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 5.0930e-04 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.9149\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.0666e-04 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.9149\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.9251e-04 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9149\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.9732e-04 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9149\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 4.8887e-04 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9149\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.8864e-04 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9149\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.8830e-04 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9149\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.8659e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9149\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.8398e-04 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9149\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 3.8875e-04 - accuracy: 1.00 - 0s 566us/step - loss: 4.9183e-04 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 4.7822e-04 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9149\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 4.8387e-04 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9149\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 4.7473e-04 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9149\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 4.7411e-04 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.9149\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 4.7917e-04 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.9149\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 4.8599e-04 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9149\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 4.7542e-04 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9149\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 4.6568e-04 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9149\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 4.6478e-04 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9149\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 4.6732e-04 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9149\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 4.6663e-04 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9149\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 4.6395e-04 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9149\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 4.5859e-04 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9149\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 831us/step - loss: 4.5533e-04 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9149\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 698us/step - loss: 4.5376e-04 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9149\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 4.5245e-04 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9149\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 4.5164e-04 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9149\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 4.5051e-04 - accuracy: 1.0000 - val_loss: 0.3020 - val_accuracy: 0.9149\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 4.5443e-04 - accuracy: 1.0000 - val_loss: 0.3020 - val_accuracy: 0.9149\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 4.4625e-04 - accuracy: 1.0000 - val_loss: 0.3010 - val_accuracy: 0.9149\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 4.4350e-04 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9149\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 4.4718e-04 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9149\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 4.4237e-04 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9149\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 4.4764e-04 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9149\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 4.4495e-04 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9149\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 4.5407e-04 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9149\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 4.4543e-04 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9149\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 4.3704e-04 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9149\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 4.3108e-04 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9149\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 4.4709e-04 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.9149\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 4.3373e-04 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9149\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 4.3811e-04 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 0.9149\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 4.2495e-04 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.9149\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 4.2301e-04 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9149\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 4.2112e-04 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9149\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 4.1894e-04 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9149\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 4.1808e-04 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.9149\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 4.2410e-04 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9149\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 4.2665e-04 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9149\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 4.1370e-04 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9149\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 4.1217e-04 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9149\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 4.1062e-04 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.9149\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 4.1732e-04 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.9149\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 4.1898e-04 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9149\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 4.0668e-04 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.9149\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 4.1039e-04 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9149\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 4.0365e-04 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9149\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 4.0255e-04 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.9149\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 4.1141e-04 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9149\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 4.0214e-04 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9149\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.9892e-04 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9149\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 3.9954e-04 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9149\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.1040e-04 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9149\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.0351e-04 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9149\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.9508e-04 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.9149\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.9213e-04 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.9149\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.9117e-04 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.9149\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.9572e-04 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.9149\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.9496e-04 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9149\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 3.9145e-04 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9149\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 3.8745e-04 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9149\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 3.8393e-04 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9149\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 3.9355e-04 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9149\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 3.8185e-04 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9149\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 3.8469e-04 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 0.9149\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 3.9081e-04 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9149\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 3.8241e-04 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9149\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 3.8697e-04 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9149\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 3.8486e-04 - accuracy: 1.0000 - val_loss: 0.3114 - val_accuracy: 0.9149\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 3.7809e-04 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.9149\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.8270e-04 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.9149\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.7573e-04 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9149\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.7018e-04 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9149\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.8048e-04 - accuracy: 1.0000 - val_loss: 0.3141 - val_accuracy: 0.9149\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.6859e-04 - accuracy: 1.0000 - val_loss: 0.3141 - val_accuracy: 0.9149\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.7186e-04 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9149\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.6541e-04 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9149\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.7420e-04 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9149\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.6868e-04 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9149\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.6465e-04 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9149\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.6036e-04 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9149\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.6060e-04 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.6718e-04 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9149\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.6820e-04 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9149\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.6256e-04 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9149\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.5770e-04 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9149\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.5370e-04 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9149\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.6399e-04 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.9149\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.5992e-04 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9149\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.5013e-04 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9149\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.5947e-04 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9149\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.5373e-04 - accuracy: 1.0000 - val_loss: 0.3176 - val_accuracy: 0.9149\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.4830e-04 - accuracy: 1.0000 - val_loss: 0.3174 - val_accuracy: 0.9149\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.4425e-04 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.9149\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.4334e-04 - accuracy: 1.0000 - val_loss: 0.3162 - val_accuracy: 0.9149\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.4450e-04 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.9149\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.4568e-04 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.9149\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 3.4978e-04 - accuracy: 1.0000 - val_loss: 0.3164 - val_accuracy: 0.9149\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 3.4574e-04 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9149\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.4634e-04 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9149\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.3825e-04 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9149\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.3596e-04 - accuracy: 1.0000 - val_loss: 0.3186 - val_accuracy: 0.9149\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.3339e-04 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9149\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.4486e-04 - accuracy: 1.0000 - val_loss: 0.3210 - val_accuracy: 0.9149\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.4072e-04 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9149\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.3173e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9149\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.2937e-04 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.9149\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.2787e-04 - accuracy: 1.0000 - val_loss: 0.3190 - val_accuracy: 0.9149\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.3779e-04 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.2967e-04 - accuracy: 1.0000 - val_loss: 0.3196 - val_accuracy: 0.9149\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.2682e-04 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 0.9149\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.2420e-04 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.9149\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.2268e-04 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.9149\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.2169e-04 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9149\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.2123e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9149\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.2703e-04 - accuracy: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.9149\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.1995e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9149\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.1857e-04 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9149\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.2773e-04 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 0.9149\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 3.1750e-04 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 0.9149\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.2111e-04 - accuracy: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.9149\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.1500e-04 - accuracy: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9149\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.1433e-04 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9149\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 3.1774e-04 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9149\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.1145e-04 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9149\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.1086e-04 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9149\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 3.1462e-04 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9149\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0823e-04 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9149\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.1103e-04 - accuracy: 1.0000 - val_loss: 0.3244 - val_accuracy: 0.9149\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.1399e-04 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9149\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0663e-04 - accuracy: 1.0000 - val_loss: 0.3247 - val_accuracy: 0.9149\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0775e-04 - accuracy: 1.0000 - val_loss: 0.3253 - val_accuracy: 0.9149\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.1307e-04 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.9149\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0585e-04 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.9149\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.0285e-04 - accuracy: 1.0000 - val_loss: 0.3272 - val_accuracy: 0.9149\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0117e-04 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9149\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0205e-04 - accuracy: 1.0000 - val_loss: 0.3288 - val_accuracy: 0.9149\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.0287e-04 - accuracy: 1.0000 - val_loss: 0.3291 - val_accuracy: 0.9149\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0079e-04 - accuracy: 1.0000 - val_loss: 0.3290 - val_accuracy: 0.9149\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.9886e-04 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 0.9149\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.9606e-04 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9149\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.0256e-04 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9149\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.9882e-04 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9149\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.9387e-04 - accuracy: 1.0000 - val_loss: 0.3291 - val_accuracy: 0.9149\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.9267e-04 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 0.9149\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.9050e-04 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9149\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.9127e-04 - accuracy: 1.0000 - val_loss: 0.3321 - val_accuracy: 0.9149\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.9420e-04 - accuracy: 1.0000 - val_loss: 0.3327 - val_accuracy: 0.9149\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0418e-04 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9149\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.9760e-04 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9149\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.0274e-04 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9149\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 2.8600e-04 - accuracy: 1.0000 - val_loss: 0.3313 - val_accuracy: 0.9149\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.8507e-04 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9149\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.8631e-04 - accuracy: 1.0000 - val_loss: 0.3306 - val_accuracy: 0.9149\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.8511e-04 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.9149\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.9388e-04 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 0.9149\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 2.9114e-04 - accuracy: 1.0000 - val_loss: 0.3306 - val_accuracy: 0.9149\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 2.8318e-04 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9149\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 2.8188e-04 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9149\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 2.7901e-04 - accuracy: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9149\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 2.7808e-04 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 0.9149\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 2.8376e-04 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9149\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.8140e-04 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9149\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.7548e-04 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.9149\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.7910e-04 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9149\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.8017e-04 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9149\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.7682e-04 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9149\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.7190e-04 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9149\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.7780e-04 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9149\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.7056e-04 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9149\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.6970e-04 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.9149\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.6824e-04 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9149\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.6784e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9149\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.6711e-04 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9149\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.7069e-04 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9149\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.6676e-04 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 0.9149\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.6454e-04 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9149\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.7191e-04 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9149\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.6502e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9149\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.6661e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9149\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.6271e-04 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.9149\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.6055e-04 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9149\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 622us/step - loss: 2.6740e-04 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9149\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.6048e-04 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9149\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 2.6157e-04 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.9149\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 2.5826e-04 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9149\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 2.6423e-04 - accuracy: 1.0000 - val_loss: 0.3379 - val_accuracy: 0.9149\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.6012e-04 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.9149\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.6080e-04 - accuracy: 1.0000 - val_loss: 0.3379 - val_accuracy: 0.9149\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.6062e-04 - accuracy: 1.0000 - val_loss: 0.3387 - val_accuracy: 0.9149\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.5698e-04 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9149\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.5334e-04 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9149\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.5285e-04 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9149\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.5218e-04 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9149\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.5155e-04 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9149\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.5011e-04 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9149\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.4952e-04 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9149\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.4843e-04 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9149\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.4798e-04 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9149\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.4731e-04 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9149\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.4966e-04 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9149\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.5135e-04 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9149\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.4500e-04 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9149\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.4721e-04 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9149\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.4910e-04 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9149\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.4269e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9149\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.4195e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9149\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.4146e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9149\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.4064e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9149\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.4300e-04 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9149\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.4014e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9149\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.3819e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9149\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.3981e-04 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9149\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.4128e-04 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9149\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.4061e-04 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9149\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.4067e-04 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9149\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 2.4473e-04 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9149\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 2.3856e-04 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 2.3536e-04 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.9149\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 2.3370e-04 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.9149\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.3310e-04 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9149\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.3983e-04 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9149\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.3450e-04 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9149\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.3248e-04 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9149\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.3532e-04 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9149\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.2898e-04 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9149\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.2822e-04 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9149\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.2752e-04 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9149\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.2922e-04 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9149\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.3119e-04 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.9149\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.2570e-04 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9149\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.2523e-04 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9149\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.2829e-04 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9149\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.2795e-04 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9149\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.2321e-04 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9149\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 2.2251e-04 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9149\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 2.2189e-04 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9149\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.2479e-04 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9149\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.2094e-04 - accuracy: 1.0000 - val_loss: 0.3492 - val_accuracy: 0.9149\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 2.1989e-04 - accuracy: 1.0000 - val_loss: 0.3492 - val_accuracy: 0.9149\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 2.1957e-04 - accuracy: 1.0000 - val_loss: 0.3492 - val_accuracy: 0.9149\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 2.1910e-04 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.9149\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.2120e-04 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9149\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 2.1951e-04 - accuracy: 1.0000 - val_loss: 0.3495 - val_accuracy: 0.9149\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 2.1745e-04 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.9149\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 2.2208e-04 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9149\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.2138e-04 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9149\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.1609e-04 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9149\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.1536e-04 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9149\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.1797e-04 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9149\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.1711e-04 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.9149\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.1328e-04 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9149\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.1250e-04 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.9149\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.1321e-04 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9149\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.1135e-04 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.9149\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.1118e-04 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9149\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.1115e-04 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9149\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.1083e-04 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9149\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.1023e-04 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9149\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 2.1256e-04 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9149\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.1056e-04 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9149\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.1231e-04 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9149\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.0777e-04 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9149\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.0841e-04 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9149\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.0574e-04 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9149\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.0561e-04 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9149\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.0653e-04 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.9149\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.0789e-04 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9149\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.0717e-04 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9149\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.0667e-04 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9149\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.0608e-04 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9149\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.0582e-04 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9149\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.0431e-04 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9149\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 2.0263e-04 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9149\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 2.0111e-04 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.9149\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.0022e-04 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9149\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 1.9957e-04 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.9149\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.0280e-04 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.9149\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 1.9877e-04 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9149\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 850us/step - loss: 1.9831e-04 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.9149\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 1.9752e-04 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9149\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.9702e-04 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.9149\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.9657e-04 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9149\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.9885e-04 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.9149\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.9960e-04 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9149\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.9726e-04 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.9149\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.9864e-04 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9149\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.9618e-04 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9149\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.9324e-04 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9149\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.9379e-04 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9149\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.9789e-04 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.9149\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.9276e-04 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9149\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.9390e-04 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9149\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.9096e-04 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.9149\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.9443e-04 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9149\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.8968e-04 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9149\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.9157e-04 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9149\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.8872e-04 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.9149\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.8832e-04 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9149\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.8793e-04 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9149\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.8748e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9149\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.8893e-04 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9149\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.9069e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9149\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 1.8550e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9149\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 1.8758e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9149\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 1.8472e-04 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.9149\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.8538e-04 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9149\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.8380e-04 - accuracy: 1.0000 - val_loss: 0.3627 - val_accuracy: 0.9149\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 1.8390e-04 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.9149\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 1.8382e-04 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9149\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.8337e-04 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9149\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.8440e-04 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9149\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.8634e-04 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.9149\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.8075e-04 - accuracy: 1.0000 - val_loss: 0.3627 - val_accuracy: 0.9149\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.8044e-04 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.9149\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 1.7990e-04 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.9149\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.7960e-04 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.9149\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.8107e-04 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9149\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.7861e-04 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9149\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.8161e-04 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.9149\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.7780e-04 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9149\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.7886e-04 - accuracy: 1.0000 - val_loss: 0.3643 - val_accuracy: 0.9149\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 1.8055e-04 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9149\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.7632e-04 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9149\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 1.7782e-04 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9149\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.7624e-04 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.9149\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 1.7508e-04 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.7475e-04 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.9149\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 1.8039e-04 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9149\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 1.7887e-04 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9149\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 681us/step - loss: 1.7605e-04 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.9149\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 1.7353e-04 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9149\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 616us/step - loss: 1.7188e-04 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9149\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 850us/step - loss: 1.7743e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9149\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 1.7260e-04 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9149\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.7236e-04 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9149\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.7285e-04 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9149\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 1.7084e-04 - accuracy: 1.0000 - val_loss: 0.3671 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2c4b6465f8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(500,activation=\"sigmoid\"))\n",
    "model.add(Dense(200,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Do poniszego modelu dodaj\n",
    " \n",
    "```python\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.3))\n",
    "```\n",
    "\n",
    "w kadej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki:\n",
    "\n",
    "* porwnaj krzywe uczenia\n",
    "* narysuj granice decyzyjne (dane s w 2D)\n",
    "* porwnaj do powyszego eksperymentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularyzacja\n",
    "\n",
    "# Zad.\n",
    "Do modelu dodaj \n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l1(0.00001)))\n",
    "```\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l1(0.0001)))\n",
    "```\n",
    "\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l2(0.00001)))\n",
    "```\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l2(0.0001)))\n",
    "```\n",
    "\n",
    "w kadej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki dla obu modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.8459 - accuracy: 0.5472 - val_loss: 0.8222 - val_accuracy: 0.4468\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.7898 - accuracy: 0.4906 - val_loss: 0.7719 - val_accuracy: 0.5532\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.8100 - accuracy: 0.4528 - val_loss: 0.7439 - val_accuracy: 0.6170\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.7288 - accuracy: 0.7547 - val_loss: 0.7805 - val_accuracy: 0.4468\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.7237 - accuracy: 0.5472 - val_loss: 0.8047 - val_accuracy: 0.4468\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 265us/step - loss: 0.7268 - accuracy: 0.5472 - val_loss: 0.7371 - val_accuracy: 0.5532\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.6677 - accuracy: 0.7170 - val_loss: 0.6624 - val_accuracy: 0.7234\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 599us/step - loss: 0.6293 - accuracy: 0.8302 - val_loss: 0.6468 - val_accuracy: 0.7447\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 497us/step - loss: 0.6016 - accuracy: 0.8113 - val_loss: 0.6208 - val_accuracy: 0.7660\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 674us/step - loss: 0.5586 - accuracy: 0.8491 - val_loss: 0.5899 - val_accuracy: 0.7447\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.5173 - accuracy: 0.8302 - val_loss: 0.5749 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.4883 - accuracy: 0.8302 - val_loss: 0.5673 - val_accuracy: 0.7447\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.4609 - accuracy: 0.8491 - val_loss: 0.5721 - val_accuracy: 0.7447\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.4380 - accuracy: 0.8491 - val_loss: 0.5884 - val_accuracy: 0.7447\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.4286 - accuracy: 0.8679 - val_loss: 0.6098 - val_accuracy: 0.7660\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4181 - accuracy: 0.8679 - val_loss: 0.6198 - val_accuracy: 0.7660\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.4061 - accuracy: 0.8679 - val_loss: 0.6278 - val_accuracy: 0.7872\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 484us/step - loss: 0.3982 - accuracy: 0.8679 - val_loss: 0.6248 - val_accuracy: 0.7872\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 745us/step - loss: 0.3880 - accuracy: 0.8679 - val_loss: 0.6190 - val_accuracy: 0.7872\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3776 - accuracy: 0.8679 - val_loss: 0.6018 - val_accuracy: 0.7872\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3675 - accuracy: 0.8679 - val_loss: 0.5759 - val_accuracy: 0.8085\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3585 - accuracy: 0.8868 - val_loss: 0.5567 - val_accuracy: 0.8298\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3532 - accuracy: 0.8868 - val_loss: 0.5451 - val_accuracy: 0.8298\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3431 - accuracy: 0.8868 - val_loss: 0.5484 - val_accuracy: 0.8298\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3485 - accuracy: 0.9057 - val_loss: 0.5638 - val_accuracy: 0.8085\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.3357 - accuracy: 0.9057 - val_loss: 0.5540 - val_accuracy: 0.7872\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3358 - accuracy: 0.8868 - val_loss: 0.5369 - val_accuracy: 0.8085\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3272 - accuracy: 0.9057 - val_loss: 0.5384 - val_accuracy: 0.8085\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3245 - accuracy: 0.8868 - val_loss: 0.5456 - val_accuracy: 0.8298\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3206 - accuracy: 0.9057 - val_loss: 0.5478 - val_accuracy: 0.8298\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3175 - accuracy: 0.9057 - val_loss: 0.5482 - val_accuracy: 0.8298\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3155 - accuracy: 0.9057 - val_loss: 0.5562 - val_accuracy: 0.8298\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3112 - accuracy: 0.8868 - val_loss: 0.5560 - val_accuracy: 0.8298\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.90 - 0s 548us/step - loss: 0.3107 - accuracy: 0.8868 - val_loss: 0.5647 - val_accuracy: 0.8085\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3057 - accuracy: 0.8868 - val_loss: 0.5575 - val_accuracy: 0.8298\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.3029 - accuracy: 0.8868 - val_loss: 0.5541 - val_accuracy: 0.8298\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3016 - accuracy: 0.8868 - val_loss: 0.5576 - val_accuracy: 0.8298\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2983 - accuracy: 0.8868 - val_loss: 0.5540 - val_accuracy: 0.8298\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2957 - accuracy: 0.9057 - val_loss: 0.5428 - val_accuracy: 0.8298\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2935 - accuracy: 0.9057 - val_loss: 0.5410 - val_accuracy: 0.8298\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2920 - accuracy: 0.9057 - val_loss: 0.5416 - val_accuracy: 0.8298\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2900 - accuracy: 0.9057 - val_loss: 0.5401 - val_accuracy: 0.8298\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2860 - accuracy: 0.9057 - val_loss: 0.5500 - val_accuracy: 0.8298\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2841 - accuracy: 0.9057 - val_loss: 0.5612 - val_accuracy: 0.8298\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2833 - accuracy: 0.9245 - val_loss: 0.5611 - val_accuracy: 0.8085\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2816 - accuracy: 0.9245 - val_loss: 0.5463 - val_accuracy: 0.8298\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2778 - accuracy: 0.9057 - val_loss: 0.5324 - val_accuracy: 0.8298\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.2782 - accuracy: 0.9245 - val_loss: 0.5213 - val_accuracy: 0.8298\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2729 - accuracy: 0.9245 - val_loss: 0.5261 - val_accuracy: 0.8298\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2709 - accuracy: 0.9245 - val_loss: 0.5233 - val_accuracy: 0.8298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2701 - accuracy: 0.9245 - val_loss: 0.5264 - val_accuracy: 0.8298\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2667 - accuracy: 0.9434 - val_loss: 0.5145 - val_accuracy: 0.8298\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.2639 - accuracy: 0.9245 - val_loss: 0.5009 - val_accuracy: 0.8298\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2613 - accuracy: 0.9245 - val_loss: 0.4945 - val_accuracy: 0.8298\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2601 - accuracy: 0.9245 - val_loss: 0.4905 - val_accuracy: 0.8298\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2571 - accuracy: 0.9245 - val_loss: 0.4945 - val_accuracy: 0.8298\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2555 - accuracy: 0.9245 - val_loss: 0.5061 - val_accuracy: 0.8298\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 560us/step - loss: 0.2534 - accuracy: 0.9623 - val_loss: 0.5041 - val_accuracy: 0.8298\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2501 - accuracy: 0.9623 - val_loss: 0.4940 - val_accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2471 - accuracy: 0.9623 - val_loss: 0.4858 - val_accuracy: 0.8298\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2461 - accuracy: 0.9434 - val_loss: 0.4850 - val_accuracy: 0.8298\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2420 - accuracy: 0.9434 - val_loss: 0.4732 - val_accuracy: 0.8511\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 341us/step - loss: 0.2410 - accuracy: 0.9245 - val_loss: 0.4681 - val_accuracy: 0.8511\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2382 - accuracy: 0.9245 - val_loss: 0.4711 - val_accuracy: 0.8511\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2350 - accuracy: 0.9623 - val_loss: 0.4860 - val_accuracy: 0.8511\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.2325 - accuracy: 0.9623 - val_loss: 0.4938 - val_accuracy: 0.8511\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 303us/step - loss: 0.2317 - accuracy: 0.9623 - val_loss: 0.4896 - val_accuracy: 0.8511\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2285 - accuracy: 0.9623 - val_loss: 0.4731 - val_accuracy: 0.8511\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2239 - accuracy: 0.9623 - val_loss: 0.4590 - val_accuracy: 0.8511\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 466us/step - loss: 0.2210 - accuracy: 0.9623 - val_loss: 0.4430 - val_accuracy: 0.8511\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2196 - accuracy: 0.9623 - val_loss: 0.4295 - val_accuracy: 0.8511\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 649us/step - loss: 0.2172 - accuracy: 0.9434 - val_loss: 0.4254 - val_accuracy: 0.8511\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.2139 - accuracy: 0.9623 - val_loss: 0.4342 - val_accuracy: 0.8723\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.2113 - accuracy: 0.9811 - val_loss: 0.4351 - val_accuracy: 0.8936\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.2095 - accuracy: 0.9811 - val_loss: 0.4196 - val_accuracy: 0.8936\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2059 - accuracy: 0.9811 - val_loss: 0.3928 - val_accuracy: 0.8511\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.2022 - accuracy: 0.9811 - val_loss: 0.3788 - val_accuracy: 0.8511\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2008 - accuracy: 0.9623 - val_loss: 0.3753 - val_accuracy: 0.8511\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1964 - accuracy: 0.9623 - val_loss: 0.3830 - val_accuracy: 0.8723\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1937 - accuracy: 0.9811 - val_loss: 0.3840 - val_accuracy: 0.8723\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1894 - accuracy: 0.9811 - val_loss: 0.3917 - val_accuracy: 0.8936\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.1898 - accuracy: 0.9811 - val_loss: 0.3949 - val_accuracy: 0.8936\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1876 - accuracy: 0.9811 - val_loss: 0.3760 - val_accuracy: 0.8936\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.1816 - accuracy: 0.9811 - val_loss: 0.3613 - val_accuracy: 0.8723\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.1796 - accuracy: 0.9811 - val_loss: 0.3429 - val_accuracy: 0.8723\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1770 - accuracy: 0.9811 - val_loss: 0.3354 - val_accuracy: 0.8936\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1754 - accuracy: 0.9811 - val_loss: 0.3241 - val_accuracy: 0.8936\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 646us/step - loss: 0.1718 - accuracy: 0.9811 - val_loss: 0.3260 - val_accuracy: 0.8936\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1725 - accuracy: 0.9811 - val_loss: 0.3351 - val_accuracy: 0.8936\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1669 - accuracy: 0.9811 - val_loss: 0.3260 - val_accuracy: 0.8936\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1636 - accuracy: 0.9811 - val_loss: 0.3183 - val_accuracy: 0.8936\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1608 - accuracy: 0.9811 - val_loss: 0.3153 - val_accuracy: 0.8936\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1607 - accuracy: 0.9811 - val_loss: 0.3131 - val_accuracy: 0.8936\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1570 - accuracy: 0.9811 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1547 - accuracy: 0.9811 - val_loss: 0.2945 - val_accuracy: 0.8936\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.1533 - accuracy: 0.9811 - val_loss: 0.2970 - val_accuracy: 0.8936\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.1507 - accuracy: 0.9811 - val_loss: 0.2951 - val_accuracy: 0.8936\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.1485 - accuracy: 0.9811 - val_loss: 0.2953 - val_accuracy: 0.9149\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1462 - accuracy: 0.9811 - val_loss: 0.2976 - val_accuracy: 0.9149\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1447 - accuracy: 0.9811 - val_loss: 0.2983 - val_accuracy: 0.9149\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1434 - accuracy: 0.9811 - val_loss: 0.2949 - val_accuracy: 0.9149\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1423 - accuracy: 0.9811 - val_loss: 0.2903 - val_accuracy: 0.9149\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1407 - accuracy: 0.9811 - val_loss: 0.2743 - val_accuracy: 0.9149\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1389 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9149\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1363 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9149\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1343 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9149\n",
      "Epoch 107/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1326 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9149\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9149\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1312 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1291 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9149\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1271 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9149\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1269 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.8936\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1246 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9149\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1232 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1242 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9149\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.1220 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9149\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 944us/step - loss: 0.1190 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9149\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 850us/step - loss: 0.1180 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9149\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9149\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.1170 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9149\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9149\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.1148 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9149\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.1136 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.1140 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9149\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.1121 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9362\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.1115 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9362\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.1110 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9362\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.1099 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9362\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 718us/step - loss: 0.1095 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9362\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9362\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1084 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9362\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1075 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.8936\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.8936\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.1062 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9149\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 887us/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9362\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 850us/step - loss: 0.1040 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9149\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9149\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 869us/step - loss: 0.1036 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1019 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1014 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9149\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1005 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9362\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9362\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.1007 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9362\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0992 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9149\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0985 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.8936\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.8936\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.8936\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0970 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9149\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9362\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0969 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9362\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9362\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0967 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.8936\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9149\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0950 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.8936\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9149\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.8936\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9149\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0929 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9362\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0927 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9149\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0920 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.8936\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 604us/step - loss: 0.0918 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.8936\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.8936\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.8936\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.8936\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.8936\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 963us/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.8936\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.8936\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0888 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.8936\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.8936\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.8936\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0875 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.8936\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.8936\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 718us/step - loss: 0.0868 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.8936\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.8936\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0864 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.8936\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0860 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.8936\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0853 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.8936\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.8936\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.8936\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.8936\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.8936\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.8936\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.8936\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.8936\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.8936\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.8936\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.8936\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.8936\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.8936\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.8936\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.8936\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.8936\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.8936\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.8936\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.8936\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.8936\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.8936\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 850us/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.8936\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 869us/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.8936\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8936\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.8936\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.8936\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.8936\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.8936\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.8936\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 850us/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.8936\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.8936\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.8936\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.8936\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.8936\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.8936\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.8936\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.8936\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0754 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.8936\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.8936\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.8936\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.8936\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.8936\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.8936\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.8936\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.8936\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.8936\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.8936\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.8936\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.8936\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.8936\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.8936\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.8936\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.8936\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.8936\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.8936\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.8936\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.8936\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.8936\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.8936\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.8936\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.8936\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0714 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.8936\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.8936\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.8936\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0706 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.8936\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.8936\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.8936\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.8936\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.8936\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.8936\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.8936\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.8936\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.8936\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.8936\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.8936\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.8936\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.8936\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.8936\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.8936\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.8936\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.8936\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.8936\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.8936\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.8936\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.8936\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.8936\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.8936\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.8936\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.8936\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.8936\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.8936\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.8936\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.8936\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.8936\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.8936\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.8936\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 473us/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.8936\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 692us/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.8936\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.8936\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 1.00 - 0s 529us/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.8936\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.8936\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.8936\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.8936\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.8936\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.8936\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.8936\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.8936\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.8936\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.8936\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.8936\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.8936\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.8936\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.8936\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.8936\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8936\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.8936\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.8936\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.8936\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8936\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.8936\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.8936\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.8936\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.8936\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8936\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.8936\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.8936\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.8936\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8936\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.8936\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.8936\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.8936\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.8936\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.8936\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.8936\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.8936\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.8936\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.8936\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 552us/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.8936\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 558us/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8936\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.8936\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 1.00 - 0s 585us/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8936\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 492us/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8936\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.8936\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.8936\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8936\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.8936\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.8936\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.8936\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.8936\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.8936\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.8936\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.8936\n",
      "Epoch 331/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.8936\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.8936\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.8936\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.8936\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.8936\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 848us/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.8936\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 322us/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.8936\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.8936\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 1.00 - 0s 897us/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 1.00 - 0s 529us/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.8936\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.8936\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.8936\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.8936\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.8936\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.8936\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 384us/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.8936\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.8936\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 724us/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.8936\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 336us/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.8936\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 801us/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.8936\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.8936\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 410us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.8936\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 668us/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 392us/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.8936\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.8936\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.8936\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.8936\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.8936\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.8936\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.8936\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 806us/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.8936\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.8936\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.8936\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.8936\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.8936\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.8936\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.8936\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.8936\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.8936\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.8936\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.8936\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.8936\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.8936\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.8936\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.8936\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.8936\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3127 - val_accuracy: 0.8936\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.8936\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 548us/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.8936\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 314us/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.8936\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.8936\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 825us/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.8936\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.8936\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.8936\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 0.8936\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.8936\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 0.8936\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.8936\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.8936\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.8936\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.8936\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.8936\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.8936\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.8936\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 0.8936\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.8936\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.8936\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.8936\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.8936\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.8936\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.8936\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.8936\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.8936\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.8936\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.8936\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.8936\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.8936\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.8936\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.8936\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.8936\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.8936\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.8936\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.8936\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.8936\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.8936\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.8936\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.8936\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.8936\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.8936\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 400us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.8936\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.8936\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.8936\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.8936\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 649us/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.8936\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.8936\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.8936\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.8936\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.8936\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.8936\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.8936\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.8936\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.8936\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 0.8936\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.8936\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.8936\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.8936\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.8936\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 0.8936\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.8936\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.8936\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.8936\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.8936\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 314us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.8936\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.8936\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.8936\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.8936\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 860us/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.8936\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.8936\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.8936\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 317us/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.8936\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.8936\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.8936\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 0.8936\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.8936\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.8936\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 409us/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.8936\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.8936\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.8936\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.8936\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.8936\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.8936\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.8936\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.8936\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.8936\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.8936\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.8936\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 760us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8936\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8936\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8936\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8936\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9149\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.8936\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.8936\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.8936\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.8936\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8936\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8936\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.8936\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8936\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8936\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.8936\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 467us/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8936\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.8936\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.8936\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 492us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.8936\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9149\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9149\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9149\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.8936\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.8936\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9149\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9149\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9149\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9149\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9149\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9149\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9149\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9149\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9149\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9149\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9149\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9149\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9149\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9149\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9149\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9149\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9149\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9149\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 729us/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9149\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9149\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9149\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9149\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9149\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9149\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9149\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9149\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9149\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9149\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9149\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9149\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9149\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9149\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9149\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9149\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9149\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.9149\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9149\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.9149\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9149\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9149\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9149\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9149\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9149\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9149\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9149\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9149\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9149\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9149\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9149\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9149\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9149\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9149\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9149\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9149\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9149\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9149\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9149\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9149\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9149\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9149\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9149\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9149\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9149\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9149\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9149\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9149\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9149\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9149\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9149\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9149\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9149\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9149\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9149\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9149\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9149\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9149\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9149\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9149\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9149\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 1.00 - 0s 529us/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9149\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9149\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9149\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9149\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9149\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9149\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9149\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9149\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9149\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9149\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 354us/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9149\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9149\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9149\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9149\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9149\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9149\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9149\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9149\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9149\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9149\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9149\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9149\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9149\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9149\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9149\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9149\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9149\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9149\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9149\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9149\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9149\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9149\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9149\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9149\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9149\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 625us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9149\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9149\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 360us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9149\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9149\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9149\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9149\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9149\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9149\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9149\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9149\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9149\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9149\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9149\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9149\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9149\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9149\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9149\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9149\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9149\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9149\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 1.00 - 0s 295us/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9149\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 549us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9149\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9149\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9149\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9149\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9149\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9149\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9149\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9149\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9149\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9149\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9149\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9149\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9149\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9149\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9149\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9149\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9149\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9149\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9149\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9149\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9149\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9149\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9149\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9149\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9149\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9149\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9149\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9149\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9149\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9149\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 697us/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9149\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9149\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9149\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9149\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 315us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9149\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9149\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9149\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9149\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9149\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9149\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9149\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9149\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9149\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9149\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9149\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9149\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9149\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9149\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9149\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 1.00 - 0s 295us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9149\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9149\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9149\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9149\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9149\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9149\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9149\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9149\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9149\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9149\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 609us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9149\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9149\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 578us/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9149\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9149\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9149\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9149\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9149\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9149\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9149\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9149\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9149\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9149\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9149\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 831us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9149\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9149\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9149\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9149\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9149\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9149\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9149\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9149\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9149\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9149\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9149\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9149\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9149\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9149\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9149\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9149\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9149\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9149\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9149\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9149\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9149\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9149\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9149\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9149\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9149\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9149\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9149\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9149\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9149\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9149\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9149\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9149\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9149\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 718us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9149\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9149\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9149\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9149\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9149\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9149\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9149\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9149\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9149\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9149\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9149\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9149\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9149\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9149\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9149\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9149\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9149\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9149\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9149\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9149\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9149\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9149\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9149\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9149\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9149\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9149\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9149\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9149\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9149\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9149\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9149\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9149\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9149\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9149\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9149\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9149\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9149\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9149\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9149\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 1.00 - 0s 829us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9149\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9149\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9149\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9149\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9149\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9149\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9149\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9149\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9149\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 1.00 - 0s 247us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9149\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9149\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9149\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9149\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9149\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9149\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9149\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 1.00 - 0s 295us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9149\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9149\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
      "Epoch 832/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 295us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9149\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9149\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 776us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9149\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9149\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 246us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9149\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9149\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9149\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 615us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9149\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2315 - val_accuracy: 0.9149\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 656us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9149\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9149\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9149\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9149\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9149\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9149\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9149\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9149\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9149\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9149\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9149\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9149\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9149\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9149\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9149\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9149\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9149\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9149\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9149\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9149\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9149\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9149\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9149\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9149\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9149\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9149\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9149\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9149\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9149\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9149\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9149\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9149\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9149\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9149\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9149\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9149\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9149\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9149\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9149\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9149\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9149\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9149\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9149\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9149\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9149\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9149\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9149\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9149\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9149\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9149\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9149\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9149\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9149\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9149\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9149\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9149\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9149\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9149\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9149\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9149\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9362\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 521us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9362\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9362\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9362\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 353us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9149\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9149\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 676us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9149\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 447us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9149\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9149\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9149\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9149\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9149\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9149\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9149\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9149\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9149\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9149\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9149\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9149\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 636us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9149\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9149\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 944/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 491us/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9362\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9149\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9149\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9149\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9149\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9149\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9149\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9149\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9149\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9149\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9149\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9149\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9149\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9149\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9362\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9362\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9362\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9362\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9362\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9362\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9362\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9149\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9149\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9149\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9149\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9149\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9149\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9149\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9362\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9362\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9362\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9149\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9149\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9149\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6fb0cdc898>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "from keras.regularizers import l1\n",
    "\n",
    "\n",
    "history_Adam_2 = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],), activity_regularizer=l1(0.00001)))\n",
    "model.add(Dense(500,activation=\"sigmoid\", activity_regularizer=l1(0.00001)))\n",
    "model.add(Dense(200,activation=\"sigmoid\", activity_regularizer=l1(0.00001)))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "# plt.plot(history_Adam_1.history['loss'], label = \"tarina dropout\")\n",
    "# plt.plot(history_Adam_1.history['val_loss'], label = \"test dropout\")\n",
    "\n",
    "plt.plot(history_Adam_2.history['loss'], label = \"tarina l1\")\n",
    "plt.plot(history_Adam_2.history['val_loss'], label = \"test l1\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
